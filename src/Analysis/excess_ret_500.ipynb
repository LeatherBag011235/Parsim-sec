{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import os\n",
    "import re\n",
    "import urllib.parse\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import math \n",
    "import pyarrow\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect scores from hard memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "AEE\n",
      "AKAM\n",
      "ALGN\n",
      "AME\n",
      "AMT\n",
      "AMZN\n",
      "ANSS\n",
      "ARE\n",
      "AXON\n",
      "BAX\n",
      "BBWI\n",
      "BBY\n",
      "BDX\n",
      "BEN\n",
      "BF-B\n",
      "BIIB\n",
      "BIO\n",
      "BK\n",
      "BKNG\n",
      "BKR\n",
      "BLDR\n",
      "BLK\n",
      "BMY\n",
      "BR\n",
      "BRK-B\n",
      "BRO\n",
      "BSX\n",
      "BX\n",
      "BXP\n",
      "C\n",
      "CB\n",
      "CBOE\n",
      "CBRE\n",
      "CCI\n",
      "CCL\n",
      "CDNS\n",
      "CDW\n",
      "CE\n",
      "CF\n",
      "CFG\n",
      "CHD\n",
      "CHRW\n",
      "CHTR\n",
      "CI\n",
      "CINF\n",
      "CL\n",
      "CLX\n",
      "CME\n",
      "CMG\n",
      "CMI\n",
      "CMS\n",
      "CNC\n",
      "CNP\n",
      "COF\n",
      "COO\n",
      "COP\n",
      "COR\n",
      "COST\n",
      "CPB\n",
      "CPRT\n",
      "CPT\n",
      "CRL\n",
      "CRM\n",
      "CSCO\n",
      "CSGP\n",
      "CSX\n",
      "CTLT\n",
      "CTSH\n",
      "CVS\n",
      "CVX\n",
      "CZR\n",
      "D\n",
      "DD\n",
      "DE\n",
      "DECK\n",
      "DFS\n",
      "DG\n",
      "DGX\n",
      "DHI\n",
      "DHR\n",
      "DIS\n",
      "DLR\n",
      "DLTR\n",
      "DOC\n",
      "DOV\n",
      "DOW\n",
      "DPZ\n",
      "DRI\n",
      "DTE\n",
      "DUK\n",
      "DVN\n",
      "DXCM\n",
      "EBAY\n",
      "ECL\n",
      "ED\n",
      "EFX\n",
      "EG\n",
      "EIX\n",
      "EL\n",
      "EMN\n",
      "EMR\n",
      "ENPH\n",
      "EOG\n",
      "EQIX\n",
      "EQR\n",
      "EQT\n",
      "ES\n",
      "ESS\n",
      "ETN\n",
      "ETR\n",
      "ETSY\n",
      "EVRG\n",
      "EW\n",
      "EXC\n",
      "EXPD\n",
      "EXPE\n",
      "EXR\n",
      "F\n",
      "FCX\n",
      "FDS\n",
      "FDX\n",
      "FE\n",
      "FFIV\n",
      "FI\n",
      "FICO\n",
      "FIS\n",
      "FITB\n",
      "FMC\n",
      "FRT\n",
      "FSLR\n",
      "FTNT\n",
      "FTV\n",
      "GD\n",
      "GE\n",
      "GEHC\n",
      "GEN\n",
      "GILD\n",
      "GIS\n",
      "GL\n",
      "GLW\n",
      "GM\n",
      "GNRC\n",
      "GOOGL\n",
      "GPC\n",
      "GPN\n",
      "GRMN\n",
      "GS\n",
      "GWW\n",
      "HD\n",
      "HES\n",
      "HIG\n",
      "HII\n",
      "HLT\n",
      "HOLX\n",
      "HPE\n",
      "HPQ\n",
      "HSIC\n",
      "HST\n",
      "HSY\n",
      "HUBB\n",
      "HUM\n",
      "HWM\n",
      "IBM\n",
      "ICE\n",
      "IDXX\n",
      "IEX\n",
      "IFF\n",
      "ILMN\n",
      "INCY\n",
      "INTC\n",
      "INTU\n",
      "INVH\n",
      "IP\n",
      "IPG\n",
      "IQV\n",
      "IR\n",
      "IRM\n",
      "ISRG\n",
      "IT\n",
      "ITW\n",
      "IVZ\n",
      "J\n",
      "JBHT\n",
      "JBL\n",
      "JCI\n",
      "JKHY\n",
      "JNJ\n",
      "JNPR\n",
      "JPM\n",
      "K\n",
      "KDP\n",
      "KEY\n",
      "KEYS\n",
      "KHC\n",
      "KIM\n",
      "KMB\n",
      "KMI\n",
      "KMX\n",
      "KO\n",
      "KR\n",
      "KVUE\n",
      "L\n",
      "LDOS\n",
      "LEN\n",
      "LH\n",
      "LHX\n",
      "LIN\n",
      "LKQ\n",
      "LLY\n",
      "LMT\n",
      "LNT\n",
      "LOW\n",
      "LRCX\n",
      "LULU\n",
      "LUV\n",
      "LVS\n",
      "LW\n",
      "LYB\n",
      "LYV\n",
      "MAR\n",
      "MCD\n",
      "MCHP\n",
      "MCK\n",
      "MCO\n",
      "MDLZ\n",
      "MDT\n",
      "MET\n",
      "MGM\n",
      "MHK\n",
      "MKC\n",
      "MKTX\n",
      "MLM\n",
      "MMC\n",
      "MMM\n",
      "MNST\n",
      "MO\n",
      "MOH\n",
      "MOS\n",
      "MPC\n",
      "MRK\n",
      "MRO\n",
      "MS\n",
      "MSCI\n",
      "MSFT\n",
      "MSI\n",
      "MTB\n",
      "MTCH\n",
      "MTD\n",
      "MU\n",
      "NCLH\n",
      "NDSN\n",
      "NEE\n",
      "NEM\n",
      "NFLX\n",
      "NI\n",
      "NKE\n",
      "NOC\n",
      "NOW\n",
      "NRG\n",
      "NSC\n",
      "NTAP\n",
      "NTRS\n",
      "NUE\n",
      "NVDA\n",
      "NVR\n",
      "NXPI\n",
      "O\n",
      "ODFL\n",
      "OKE\n",
      "OMC\n",
      "ON\n",
      "ORCL\n",
      "OTIS\n",
      "OXY\n",
      "PCG\n",
      "PEP\n",
      "PFG\n",
      "PG\n",
      "PGR\n",
      "PH\n",
      "PHM\n",
      "PKG\n",
      "PLD\n",
      "PM\n",
      "PNC\n",
      "PNR\n",
      "PNW\n",
      "PODD\n",
      "POOL\n",
      "PPG\n",
      "PPL\n",
      "PRU\n",
      "PSX\n",
      "PTC\n",
      "PWR\n",
      "PYPL\n",
      "QCOM\n",
      "QRVO\n",
      "RCL\n",
      "RF\n",
      "RHI\n",
      "RJF\n",
      "RL\n",
      "RMD\n",
      "ROK\n",
      "ROL\n",
      "ROP\n",
      "ROST\n",
      "RSG\n",
      "RTX\n",
      "RVTY\n",
      "SBAC\n",
      "SBUX\n",
      "SCHW\n",
      "SHW\n",
      "SJM\n",
      "SLB\n",
      "SMCI\n",
      "SNPS\n",
      "SO\n",
      "SPG\n",
      "SRE\n",
      "STE\n",
      "STLD\n",
      "STT\n",
      "STX\n",
      "STZ\n",
      "SWK\n",
      "SWKS\n",
      "SYF\n",
      "SYK\n",
      "SYY\n",
      "T\n",
      "TDG\n",
      "TDY\n",
      "TECH\n",
      "TER\n",
      "TFC\n",
      "TFX\n",
      "TGT\n",
      "TJX\n",
      "TMO\n",
      "TMUS\n",
      "TPR\n",
      "TRGP\n",
      "TRMB\n",
      "TROW\n",
      "TRV\n",
      "TSCO\n",
      "TSN\n",
      "TT\n",
      "TTWO\n",
      "TXN\n",
      "TXT\n",
      "TYL\n",
      "UAL\n",
      "UBER\n",
      "UDR\n",
      "UHS\n",
      "UNH\n",
      "UNP\n",
      "UPS\n",
      "URI\n",
      "USB\n",
      "V\n",
      "VICI\n",
      "VLO\n",
      "VLTO\n",
      "VMC\n",
      "VRSK\n",
      "VRSN\n",
      "VST\n",
      "VTR\n",
      "VTRS\n",
      "VZ\n",
      "WAT\n",
      "WBD\n",
      "WDC\n",
      "WEC\n",
      "WFC\n",
      "WM\n",
      "WMB\n",
      "WMT\n",
      "WRB\n",
      "WRK\n",
      "WST\n",
      "WTW\n",
      "WY\n",
      "XOM\n",
      "XYL\n",
      "YUM\n",
      "ZBH\n",
      "ZTS\n"
     ]
    }
   ],
   "source": [
    "root = r'C:\\Users\\310\\Desktop\\Progects_Py\\Parsim-sec\\src\\Analysis\\data\\snp_500_scores'\n",
    "\n",
    "ticker_symbol_pattern = re.compile(r'^([A-Z]+(?:\\.[A-Z]+)?)\\.parquet$')\n",
    "\n",
    "df_dict_scores = {}\n",
    "\n",
    "for dir in os.listdir(root):\n",
    "    \n",
    "    match = ticker_symbol_pattern.search(dir)\n",
    "\n",
    "    ticker = match.group(1)\n",
    "    ticker = ticker.replace('.', '-')\n",
    "    print(ticker)\n",
    "\n",
    "    file_path = os.path.join(root, dir)\n",
    "\n",
    "    df = pl.read_parquet(file_path)\n",
    "    df_dict_scores[ticker] = df \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is support func to find end prices and their dates. It takes as an arguments starting index, which is the nuber of row of hist dataframe and this hist dataframe itself. Hist dataframe contain daily OHLC data for particular ticker (company). \n",
    "\n",
    "It also cheks wether index of end price is in hist, meaning that if this particular report was released very resently (less then 8 trading days ago) it will append none values for end prices out of range of hist df instead of raising an error.\n",
    "\n",
    "It returns lists of end prices and corresponding dates (none values for prices and their dates, if they are out of range of hist df)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_end_price(start_index, hist):\n",
    "    end_price_list = []\n",
    "    end_price_date_list = []\n",
    "    \n",
    "    for x in range(2, 8):\n",
    "        idx = start_index + x\n",
    "        if idx < len(hist):\n",
    "            end_price_list.append(hist.iloc[idx]['Open'])\n",
    "            end_price_date_list.append(hist.index[idx])\n",
    "        else:\n",
    "            end_price_list.append(None)\n",
    "            end_price_date_list.append(None)\n",
    "    return end_price_list, end_price_date_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is support func to calc the regular returns. It takes start price and end_price_list as an arguments. It checks whether value in end price list is none and if it is, it appends none in returns list, instead of raising an error. So we are shure that all end price lists are of the same length, but for those prices that are not found in historical data we have none values for returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regular_returns(start_price, end_price_list):\n",
    "    retuns = []\n",
    "    for end_price in end_price_list:\n",
    "        if end_price is None:\n",
    "            retuns.append(None)\n",
    "        else:\n",
    "            ret = (end_price - start_price) / start_price * 100\n",
    "            retuns.append(ret)\n",
    "    return retuns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the support func that calc SnP500 returns. It takes_start date and end_price_date_list as and arguments and then calculate returns for this timeframes. This func also checks whether value of end_price_date_list is none (meaning that it is not found in historical data), and if it is, func will append none instead of raising an error.\n",
    "\n",
    "Now we are shure that list of snp_returns will be of equal length for all report release dates and all time frames, but for those returns that cannot be calculates due to non existent end prices we will have nones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snp_500_return(start_date, end_price_date_list, snp_price):\n",
    "\n",
    "    snp_returns = []\n",
    "\n",
    "    for end_date in end_price_date_list:\n",
    "        if end_date is None:\n",
    "            snp_returns.append(None)\n",
    "\n",
    "        else: \n",
    "            start_index = snp_price.index.get_loc(start_date)\n",
    "            start_price = snp_price.iloc[start_index]['Open']\n",
    "    \n",
    "            end_index = snp_price.index.get_loc(end_date)\n",
    "            end_price = snp_price.iloc[end_index]['Open']\n",
    "    \n",
    "            ret = (end_price - start_price) / start_price * 100\n",
    "            \n",
    "            snp_returns.append(ret)\n",
    "\n",
    "    return snp_returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is suppurt function that retrive the end quarter price. It take as an argument hist - historical price dataframe, date_str - the date of release of this particular report, df - company dataframe, with cols named with dates of releases of corresponding reports.\n",
    "\n",
    "It takes the release date for current report and checks whether it is the last date in time series or not. If it is (this mean that we are are realy close to the end of hist df) we consider the end of hist df as the end of quarter. if it is not, we take next date in company df (which is the date of releas of the next quarterly report) and see its open price, this is pricisely the end of the quarter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_end_quarter(hist, date_str, start_date, df):\n",
    "\n",
    "    col_names = df.columns\n",
    "    current_date_index = col_names.index(date_str)\n",
    "\n",
    "    if current_date_index < len(col_names) - 1:\n",
    "\n",
    "        next_date = col_names[current_date_index + 1]\n",
    "\n",
    "        next_date_time_stemp = pd.Timestamp(next_date, tz='America/New_York')\n",
    "\n",
    "        while next_date_time_stemp not in hist.index:\n",
    "\n",
    "            next_date_time_stemp += pd.Timedelta(days=1)\n",
    "    \n",
    "        end_quarter_index = hist.index.get_loc(next_date_time_stemp)\n",
    "        end_quarter_price = hist.iloc[end_quarter_index]['Open']\n",
    "        end_quarter_date = hist.index[end_quarter_index]\n",
    "\n",
    "        start_quarter_index = hist.index.get_loc(start_date)\n",
    "\n",
    "        quarter_length = end_quarter_index - start_quarter_index\n",
    "\n",
    "    else:\n",
    "        end_quarter_price = None\n",
    "        end_quarter_date = None\n",
    "        quarter_length = None\n",
    "    \n",
    "\n",
    "    return end_quarter_price, end_quarter_date, quarter_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (7, 20)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>2019-02-25</th><th>2019-04-19</th><th>2019-07-19</th><th>2019-10-18</th><th>2020-02-21</th><th>2020-05-06</th><th>2020-07-30</th><th>2020-10-22</th><th>2021-02-19</th><th>2021-04-22</th><th>2021-07-22</th><th>2021-10-21</th><th>2022-02-17</th><th>2022-04-21</th><th>2022-07-27</th><th>2022-10-20</th><th>2023-02-23</th><th>2023-04-20</th><th>2023-07-20</th><th>2023-10-19</th></tr><tr><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>-0.521221</td><td>-0.46944</td><td>-0.58069</td><td>1.254166</td><td>0.233216</td><td>-0.425524</td><td>-0.691613</td><td>-1.410764</td><td>2.404146</td><td>0.676912</td><td>-1.87811</td><td>1.300044</td><td>-0.226948</td><td>0.658182</td><td>-0.410692</td><td>-0.423182</td><td>1.931918</td><td>0.149507</td><td>-1.043665</td><td>-3.653589</td></tr><tr><td>-0.5014</td><td>-0.617147</td><td>-0.052009</td><td>1.480322</td><td>0.195302</td><td>-0.044732</td><td>-0.537194</td><td>-1.312534</td><td>1.412181</td><td>0.331834</td><td>-1.475566</td><td>0.834694</td><td>-0.778051</td><td>0.101614</td><td>0.01745</td><td>0.690335</td><td>1.002422</td><td>0.219518</td><td>-0.744781</td><td>-2.390269</td></tr><tr><td>-0.371893</td><td>-0.52589</td><td>-0.128085</td><td>1.237692</td><td>-0.325785</td><td>-0.135324</td><td>-0.136811</td><td>-1.376712</td><td>1.14943</td><td>0.457677</td><td>-0.827272</td><td>0.712174</td><td>-1.018909</td><td>0.818475</td><td>0.234388</td><td>0.718174</td><td>0.353774</td><td>-0.030854</td><td>-0.540367</td><td>-1.878629</td></tr><tr><td>-0.405512</td><td>-0.596884</td><td>-0.012625</td><td>0.688588</td><td>-0.256304</td><td>-0.221515</td><td>-0.182951</td><td>-1.149393</td><td>1.28628</td><td>0.553159</td><td>-0.967436</td><td>0.35454</td><td>-0.734228</td><td>0.469665</td><td>-0.028837</td><td>0.539634</td><td>-0.254193</td><td>-0.022062</td><td>-0.515215</td><td>-1.240332</td></tr><tr><td>-0.315088</td><td>-0.634722</td><td>-0.028278</td><td>0.492833</td><td>-0.005</td><td>-0.763551</td><td>-0.292982</td><td>-1.015855</td><td>1.090906</td><td>0.541324</td><td>-0.714552</td><td>0.126006</td><td>-0.736156</td><td>0.112581</td><td>-0.294906</td><td>0.877191</td><td>-0.150557</td><td>0.169173</td><td>-0.429714</td><td>-0.909529</td></tr><tr><td>-0.274639</td><td>-0.599864</td><td>0.099695</td><td>0.458827</td><td>-0.411151</td><td>-0.65657</td><td>-0.174843</td><td>-0.597258</td><td>0.953795</td><td>0.516846</td><td>-0.61201</td><td>0.021004</td><td>-0.609347</td><td>0.306438</td><td>-0.294928</td><td>0.683284</td><td>-0.314904</td><td>0.112915</td><td>-0.421915</td><td>-0.874399</td></tr><tr><td>-0.214851</td><td>-0.164346</td><td>0.041571</td><td>-0.132969</td><td>-0.180509</td><td>0.161621</td><td>0.095863</td><td>-0.147302</td><td>0.311011</td><td>0.085233</td><td>-0.082369</td><td>0.036754</td><td>0.154187</td><td>0.26759</td><td>0.302136</td><td>-0.00226</td><td>-0.191209</td><td>-0.207123</td><td>-0.089662</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (7, 20)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ 2019-02-2 ┆ 2019-04-1 ┆ 2019-07-1 ┆ 2019-10-1 ┆ … ┆ 2023-02-2 ┆ 2023-04-2 ┆ 2023-07-2 ┆ 2023-10- │\n",
       "│ 5         ┆ 9         ┆ 9         ┆ 8         ┆   ┆ 3         ┆ 0         ┆ 0         ┆ 19       │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│ f64       ┆ f64       ┆ f64       ┆ f64       ┆   ┆ f64       ┆ f64       ┆ f64       ┆ f64      │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ -0.521221 ┆ -0.46944  ┆ -0.58069  ┆ 1.254166  ┆ … ┆ 1.931918  ┆ 0.149507  ┆ -1.043665 ┆ -3.65358 │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 9        │\n",
       "│ -0.5014   ┆ -0.617147 ┆ -0.052009 ┆ 1.480322  ┆ … ┆ 1.002422  ┆ 0.219518  ┆ -0.744781 ┆ -2.39026 │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 9        │\n",
       "│ -0.371893 ┆ -0.52589  ┆ -0.128085 ┆ 1.237692  ┆ … ┆ 0.353774  ┆ -0.030854 ┆ -0.540367 ┆ -1.87862 │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 9        │\n",
       "│ -0.405512 ┆ -0.596884 ┆ -0.012625 ┆ 0.688588  ┆ … ┆ -0.254193 ┆ -0.022062 ┆ -0.515215 ┆ -1.24033 │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 2        │\n",
       "│ -0.315088 ┆ -0.634722 ┆ -0.028278 ┆ 0.492833  ┆ … ┆ -0.150557 ┆ 0.169173  ┆ -0.429714 ┆ -0.90952 │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 9        │\n",
       "│ -0.274639 ┆ -0.599864 ┆ 0.099695  ┆ 0.458827  ┆ … ┆ -0.314904 ┆ 0.112915  ┆ -0.421915 ┆ -0.87439 │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 9        │\n",
       "│ -0.214851 ┆ -0.164346 ┆ 0.041571  ┆ -0.132969 ┆ … ┆ -0.191209 ┆ -0.207123 ┆ -0.089662 ┆ null     │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "computing_returns(tic_sym, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a func that takes as an input a key-value pair from df_dict_scores and calculate 2-days, 3-days, 4-days, 5-days, 6-days, 7-days and full quarter excess returns for it (S&P500 is the benchmark). It stores the result as a polars df with dates of starting of the period as col names and corresponding returns as col values (seven in each: starting from 2-days down to 7-days and full quarter) - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1927-12-30 00:00:00-05:00</th>\n",
       "      <td>17.660000</td>\n",
       "      <td>17.660000</td>\n",
       "      <td>17.660000</td>\n",
       "      <td>17.660000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1928-01-03 00:00:00-05:00</th>\n",
       "      <td>17.760000</td>\n",
       "      <td>17.760000</td>\n",
       "      <td>17.760000</td>\n",
       "      <td>17.760000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1928-01-04 00:00:00-05:00</th>\n",
       "      <td>17.719999</td>\n",
       "      <td>17.719999</td>\n",
       "      <td>17.719999</td>\n",
       "      <td>17.719999</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1928-01-05 00:00:00-05:00</th>\n",
       "      <td>17.549999</td>\n",
       "      <td>17.549999</td>\n",
       "      <td>17.549999</td>\n",
       "      <td>17.549999</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1928-01-06 00:00:00-05:00</th>\n",
       "      <td>17.660000</td>\n",
       "      <td>17.660000</td>\n",
       "      <td>17.660000</td>\n",
       "      <td>17.660000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-09 00:00:00-04:00</th>\n",
       "      <td>5189.029785</td>\n",
       "      <td>5215.299805</td>\n",
       "      <td>5180.410156</td>\n",
       "      <td>5214.080078</td>\n",
       "      <td>3727370000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-10 00:00:00-04:00</th>\n",
       "      <td>5225.490234</td>\n",
       "      <td>5239.660156</td>\n",
       "      <td>5209.680176</td>\n",
       "      <td>5222.680176</td>\n",
       "      <td>3617900000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-13 00:00:00-04:00</th>\n",
       "      <td>5233.080078</td>\n",
       "      <td>5237.259766</td>\n",
       "      <td>5211.160156</td>\n",
       "      <td>5221.419922</td>\n",
       "      <td>4255710000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-14 00:00:00-04:00</th>\n",
       "      <td>5221.100098</td>\n",
       "      <td>5250.370117</td>\n",
       "      <td>5217.979980</td>\n",
       "      <td>5246.680176</td>\n",
       "      <td>4763580000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-15 00:00:00-04:00</th>\n",
       "      <td>5263.259766</td>\n",
       "      <td>5305.640137</td>\n",
       "      <td>5263.259766</td>\n",
       "      <td>5300.850098</td>\n",
       "      <td>1279391000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24209 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Open         High          Low        Close  \\\n",
       "Date                                                                            \n",
       "1927-12-30 00:00:00-05:00    17.660000    17.660000    17.660000    17.660000   \n",
       "1928-01-03 00:00:00-05:00    17.760000    17.760000    17.760000    17.760000   \n",
       "1928-01-04 00:00:00-05:00    17.719999    17.719999    17.719999    17.719999   \n",
       "1928-01-05 00:00:00-05:00    17.549999    17.549999    17.549999    17.549999   \n",
       "1928-01-06 00:00:00-05:00    17.660000    17.660000    17.660000    17.660000   \n",
       "...                                ...          ...          ...          ...   \n",
       "2024-05-09 00:00:00-04:00  5189.029785  5215.299805  5180.410156  5214.080078   \n",
       "2024-05-10 00:00:00-04:00  5225.490234  5239.660156  5209.680176  5222.680176   \n",
       "2024-05-13 00:00:00-04:00  5233.080078  5237.259766  5211.160156  5221.419922   \n",
       "2024-05-14 00:00:00-04:00  5221.100098  5250.370117  5217.979980  5246.680176   \n",
       "2024-05-15 00:00:00-04:00  5263.259766  5305.640137  5263.259766  5300.850098   \n",
       "\n",
       "                               Volume  Dividends  Stock Splits  \n",
       "Date                                                            \n",
       "1927-12-30 00:00:00-05:00           0        0.0           0.0  \n",
       "1928-01-03 00:00:00-05:00           0        0.0           0.0  \n",
       "1928-01-04 00:00:00-05:00           0        0.0           0.0  \n",
       "1928-01-05 00:00:00-05:00           0        0.0           0.0  \n",
       "1928-01-06 00:00:00-05:00           0        0.0           0.0  \n",
       "...                               ...        ...           ...  \n",
       "2024-05-09 00:00:00-04:00  3727370000        0.0           0.0  \n",
       "2024-05-10 00:00:00-04:00  3617900000        0.0           0.0  \n",
       "2024-05-13 00:00:00-04:00  4255710000        0.0           0.0  \n",
       "2024-05-14 00:00:00-04:00  4763580000        0.0           0.0  \n",
       "2024-05-15 00:00:00-04:00  1279391000        0.0           0.0  \n",
       "\n",
       "[24209 rows x 7 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snp500_ticker = yf.Ticker(\"^GSPC\")\n",
    "snp_price = snp500_ticker.history(period=\"max\", auto_adjust=True)\n",
    "snp_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computing_returns(tic_sym, df):\n",
    "\n",
    "    company_ticker = yf.Ticker(tic_sym)\n",
    "    hist = company_ticker.history(period=\"max\")\n",
    "\n",
    "    snp500_ticker = yf.Ticker(\"^GSPC\")\n",
    "    snp_price = snp500_ticker.history(period=\"max\", auto_adjust=True)\n",
    "    \n",
    "    returns = {}\n",
    "\n",
    "    for date_str in df.columns:\n",
    "\n",
    "        start_date = pd.Timestamp(date_str, tz='America/New_York')\n",
    "        \n",
    "        while start_date not in hist.index:\n",
    "\n",
    "            start_date += pd.Timedelta(days=1)\n",
    "        \n",
    "\n",
    "        start_index = hist.index.get_loc(start_date)\n",
    "\n",
    "        start_price = hist.iloc[start_index]['Open']\n",
    "\n",
    "        end_price_list, end_price_date_list = find_end_price(start_index, hist)\n",
    "        \n",
    "        if None not in end_price_list:\n",
    "            end_quarter_price, end_quarter_date, length_of_quarter = find_end_quarter(hist, date_str, start_date, df)\n",
    "            \n",
    "        else:\n",
    "            end_quarter_price = None\n",
    "            end_quarter_date = None\n",
    "\n",
    "        \n",
    "        end_price_list.append(end_quarter_price)\n",
    "        end_price_date_list.append(end_quarter_date)\n",
    "        \n",
    "        reg_returns = regular_returns(start_price, end_price_list)\n",
    "        snp_returns = snp_500_return(start_date, end_price_date_list, snp_price)\n",
    "        \n",
    "        excess_returns = [a - b if a is not None and b is not None else None for a, b in zip(reg_returns, snp_returns)]\n",
    "        \n",
    "        #normalization: divide returns for each time frame by number of trading days (2-days returns/2, 3-days returns/3, ful quarter returns/length_of_quarter)\n",
    "        timeframe_length = [2, 3, 4, 5, 6, 7, length_of_quarter]\n",
    "\n",
    "        normalized_excess_returns = [x / y if x is not None and y is not None else None for x, y in zip(excess_returns, timeframe_length)]\n",
    "\n",
    "        returns[date_str] = normalized_excess_returns\n",
    "\n",
    "    returns = pl.DataFrame(returns)\n",
    "    \n",
    "    return returns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 20)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>2019-02-25</th><th>2019-04-19</th><th>2019-07-19</th><th>2019-10-18</th><th>2020-02-21</th><th>2020-05-06</th><th>2020-07-30</th><th>2020-10-22</th><th>2021-02-19</th><th>2021-04-22</th><th>2021-07-22</th><th>2021-10-21</th><th>2022-02-17</th><th>2022-04-21</th><th>2022-07-27</th><th>2022-10-20</th><th>2023-02-23</th><th>2023-04-20</th><th>2023-07-20</th><th>2023-10-19</th></tr><tr><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>-0.101224</td><td>-0.04918</td><td>-0.031963</td><td>-0.030303</td><td>-0.227493</td><td>-0.223796</td><td>-0.295405</td><td>-0.29087</td><td>-0.260903</td><td>-0.077519</td><td>-0.097179</td><td>-0.10241</td><td>-0.229299</td><td>-0.115385</td><td>-0.010417</td><td>0.02439</td><td>-0.16792</td><td>0.0</td><td>0.043478</td><td>0.010309</td></tr><tr><td>-91.0</td><td>-9.0</td><td>-7.0</td><td>-7.0</td><td>-235.0</td><td>-79.0</td><td>-135.0</td><td>-137.0</td><td>-341.0</td><td>-20.0</td><td>-31.0</td><td>-34.0</td><td>-288.0</td><td>-24.0</td><td>-2.0</td><td>5.0</td><td>-201.0</td><td>0.0</td><td>8.0</td><td>2.0</td></tr><tr><td>0.57363</td><td>0.577068</td><td>0.562252</td><td>0.560505</td><td>0.559737</td><td>0.500294</td><td>0.469084</td><td>0.490036</td><td>0.533217</td><td>0.581062</td><td>0.55205</td><td>0.545511</td><td>0.546587</td><td>0.547689</td><td>0.552709</td><td>0.55408</td><td>0.497703</td><td>0.577011</td><td>0.543784</td><td>0.513007</td></tr><tr><td>2941.0</td><td>614.0</td><td>709.0</td><td>755.0</td><td>2975.0</td><td>851.0</td><td>1009.0</td><td>1082.0</td><td>3347.0</td><td>810.0</td><td>875.0</td><td>881.0</td><td>3291.0</td><td>557.0</td><td>561.0</td><td>584.0</td><td>2600.0</td><td>502.0</td><td>503.0</td><td>493.0</td></tr><tr><td>30577.0</td><td>6884.0</td><td>8300.0</td><td>8881.0</td><td>30650.0</td><td>10265.0</td><td>12664.0</td><td>13004.0</td><td>35747.0</td><td>8316.0</td><td>9475.0</td><td>9674.0</td><td>34138.0</td><td>7097.0</td><td>7248.0</td><td>7562.0</td><td>31666.0</td><td>6274.0</td><td>6781.0</td><td>7112.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 20)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ 2019-02-2 ┆ 2019-04-1 ┆ 2019-07-1 ┆ 2019-10-1 ┆ … ┆ 2023-02-2 ┆ 2023-04-2 ┆ 2023-07-2 ┆ 2023-10- │\n",
       "│ 5         ┆ 9         ┆ 9         ┆ 8         ┆   ┆ 3         ┆ 0         ┆ 0         ┆ 19       │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│ f64       ┆ f64       ┆ f64       ┆ f64       ┆   ┆ f64       ┆ f64       ┆ f64       ┆ f64      │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ -0.101224 ┆ -0.04918  ┆ -0.031963 ┆ -0.030303 ┆ … ┆ -0.16792  ┆ 0.0       ┆ 0.043478  ┆ 0.010309 │\n",
       "│ -91.0     ┆ -9.0      ┆ -7.0      ┆ -7.0      ┆ … ┆ -201.0    ┆ 0.0       ┆ 8.0       ┆ 2.0      │\n",
       "│ 0.57363   ┆ 0.577068  ┆ 0.562252  ┆ 0.560505  ┆ … ┆ 0.497703  ┆ 0.577011  ┆ 0.543784  ┆ 0.513007 │\n",
       "│ 2941.0    ┆ 614.0     ┆ 709.0     ┆ 755.0     ┆ … ┆ 2600.0    ┆ 502.0     ┆ 503.0     ┆ 493.0    │\n",
       "│ 30577.0   ┆ 6884.0    ┆ 8300.0    ┆ 8881.0    ┆ … ┆ 31666.0   ┆ 6274.0    ┆ 6781.0    ┆ 7112.0   │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tic_sym = \"GPC\"\n",
    "df = df_dict_scores[tic_sym]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current date2019-02-25\n",
      "next_date 2019-04-19\n",
      "next_date_time_stemp not in hist.index\n",
      "next_date_time_stemp not in hist.index\n",
      "next_date_time_stemp not in hist.index\n",
      "next_date_time_stemp 2019-04-22 00:00:00-04:00\n",
      "current date2019-04-19\n",
      "next_date 2019-07-19\n",
      "next_date_time_stemp 2019-07-19 00:00:00-04:00\n",
      "current date2019-07-19\n",
      "next_date 2019-10-18\n",
      "next_date_time_stemp 2019-10-18 00:00:00-04:00\n",
      "current date2019-10-18\n",
      "next_date 2020-02-21\n",
      "next_date_time_stemp 2020-02-21 00:00:00-05:00\n",
      "current date2020-02-21\n",
      "next_date 2020-05-06\n",
      "next_date_time_stemp 2020-05-06 00:00:00-04:00\n",
      "current date2020-05-06\n",
      "next_date 2020-07-30\n",
      "next_date_time_stemp 2020-07-30 00:00:00-04:00\n",
      "current date2020-07-30\n",
      "next_date 2020-10-22\n",
      "next_date_time_stemp 2020-10-22 00:00:00-04:00\n",
      "current date2020-10-22\n",
      "next_date 2021-02-19\n",
      "next_date_time_stemp 2021-02-19 00:00:00-05:00\n",
      "current date2021-02-19\n",
      "next_date 2021-04-22\n",
      "next_date_time_stemp 2021-04-22 00:00:00-04:00\n",
      "current date2021-04-22\n",
      "next_date 2021-07-22\n",
      "next_date_time_stemp 2021-07-22 00:00:00-04:00\n",
      "current date2021-07-22\n",
      "next_date 2021-10-21\n",
      "next_date_time_stemp 2021-10-21 00:00:00-04:00\n",
      "current date2021-10-21\n",
      "next_date 2022-02-17\n",
      "next_date_time_stemp 2022-02-17 00:00:00-05:00\n",
      "current date2022-02-17\n",
      "next_date 2022-04-21\n",
      "next_date_time_stemp 2022-04-21 00:00:00-04:00\n",
      "current date2022-04-21\n",
      "next_date 2022-07-27\n",
      "next_date_time_stemp 2022-07-27 00:00:00-04:00\n",
      "current date2022-07-27\n",
      "next_date 2022-10-20\n",
      "next_date_time_stemp 2022-10-20 00:00:00-04:00\n",
      "current date2022-10-20\n",
      "next_date 2023-02-23\n",
      "next_date_time_stemp 2023-02-23 00:00:00-05:00\n",
      "current date2023-02-23\n",
      "next_date 2023-04-20\n",
      "next_date_time_stemp 2023-04-20 00:00:00-04:00\n",
      "current date2023-04-20\n",
      "next_date 2023-07-20\n",
      "next_date_time_stemp 2023-07-20 00:00:00-04:00\n",
      "current date2023-07-20\n",
      "next_date 2023-10-19\n",
      "next_date_time_stemp 2023-10-19 00:00:00-04:00\n",
      "current date2023-10-19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (7, 20)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>2019-02-25</th><th>2019-04-19</th><th>2019-07-19</th><th>2019-10-18</th><th>2020-02-21</th><th>2020-05-06</th><th>2020-07-30</th><th>2020-10-22</th><th>2021-02-19</th><th>2021-04-22</th><th>2021-07-22</th><th>2021-10-21</th><th>2022-02-17</th><th>2022-04-21</th><th>2022-07-27</th><th>2022-10-20</th><th>2023-02-23</th><th>2023-04-20</th><th>2023-07-20</th><th>2023-10-19</th></tr><tr><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>-0.521237</td><td>-0.46944</td><td>-0.580717</td><td>1.254153</td><td>0.233225</td><td>-0.425518</td><td>-0.691627</td><td>-1.410756</td><td>2.404146</td><td>0.676922</td><td>-1.878107</td><td>1.300035</td><td>-0.226951</td><td>0.658194</td><td>-0.410686</td><td>-0.423182</td><td>1.931918</td><td>0.149511</td><td>-1.04366</td><td>-3.653592</td></tr><tr><td>-0.501419</td><td>-0.617144</td><td>-0.052021</td><td>1.480304</td><td>0.195313</td><td>-0.044728</td><td>-0.537204</td><td>-1.312534</td><td>1.412183</td><td>0.331831</td><td>-1.475564</td><td>0.834696</td><td>-0.778049</td><td>0.101624</td><td>0.01745</td><td>0.690331</td><td>1.002422</td><td>0.219518</td><td>-0.744778</td><td>-2.390267</td></tr><tr><td>-0.371901</td><td>-0.525883</td><td>-0.128101</td><td>1.237683</td><td>-0.325776</td><td>-0.135324</td><td>-0.136818</td><td>-1.376709</td><td>1.149434</td><td>0.457679</td><td>-0.82727</td><td>0.712169</td><td>-1.018909</td><td>0.818475</td><td>0.234385</td><td>0.718178</td><td>0.353777</td><td>-0.030854</td><td>-0.540364</td><td>-1.878629</td></tr><tr><td>-0.405512</td><td>-0.596879</td><td>-0.012631</td><td>0.688585</td><td>-0.2563</td><td>-0.221512</td><td>-0.182958</td><td>-1.149396</td><td>1.286287</td><td>0.553157</td><td>-0.967435</td><td>0.354539</td><td>-0.734226</td><td>0.469667</td><td>-0.028839</td><td>0.539632</td><td>-0.254195</td><td>-0.022063</td><td>-0.515213</td><td>-1.240333</td></tr><tr><td>-0.315082</td><td>-0.634715</td><td>-0.028282</td><td>0.492828</td><td>-0.004999</td><td>-0.763551</td><td>-0.292987</td><td>-1.015861</td><td>1.090908</td><td>0.541324</td><td>-0.714551</td><td>0.126008</td><td>-0.736156</td><td>0.112582</td><td>-0.294906</td><td>0.877188</td><td>-0.15056</td><td>0.169173</td><td>-0.429713</td><td>-0.909529</td></tr><tr><td>-0.27464</td><td>-0.599864</td><td>0.099686</td><td>0.458822</td><td>-0.411147</td><td>-0.656572</td><td>-0.174847</td><td>-0.597258</td><td>0.953794</td><td>0.516846</td><td>-0.612011</td><td>0.021009</td><td>-0.609346</td><td>0.306439</td><td>-0.294928</td><td>0.683283</td><td>-0.314905</td><td>0.112915</td><td>-0.421913</td><td>-0.874399</td></tr><tr><td>-0.214852</td><td>-0.164345</td><td>0.041571</td><td>-0.13297</td><td>-0.180509</td><td>0.161621</td><td>0.095863</td><td>-0.147302</td><td>0.311011</td><td>0.085233</td><td>-0.082369</td><td>0.036754</td><td>0.154187</td><td>0.26759</td><td>0.302136</td><td>-0.00226</td><td>-0.191209</td><td>-0.207123</td><td>-0.089662</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (7, 20)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ 2019-02-2 ┆ 2019-04-1 ┆ 2019-07-1 ┆ 2019-10-1 ┆ … ┆ 2023-02-2 ┆ 2023-04-2 ┆ 2023-07-2 ┆ 2023-10- │\n",
       "│ 5         ┆ 9         ┆ 9         ┆ 8         ┆   ┆ 3         ┆ 0         ┆ 0         ┆ 19       │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│ f64       ┆ f64       ┆ f64       ┆ f64       ┆   ┆ f64       ┆ f64       ┆ f64       ┆ f64      │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ -0.521237 ┆ -0.46944  ┆ -0.580717 ┆ 1.254153  ┆ … ┆ 1.931918  ┆ 0.149511  ┆ -1.04366  ┆ -3.65359 │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 2        │\n",
       "│ -0.501419 ┆ -0.617144 ┆ -0.052021 ┆ 1.480304  ┆ … ┆ 1.002422  ┆ 0.219518  ┆ -0.744778 ┆ -2.39026 │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 7        │\n",
       "│ -0.371901 ┆ -0.525883 ┆ -0.128101 ┆ 1.237683  ┆ … ┆ 0.353777  ┆ -0.030854 ┆ -0.540364 ┆ -1.87862 │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 9        │\n",
       "│ -0.405512 ┆ -0.596879 ┆ -0.012631 ┆ 0.688585  ┆ … ┆ -0.254195 ┆ -0.022063 ┆ -0.515213 ┆ -1.24033 │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 3        │\n",
       "│ -0.315082 ┆ -0.634715 ┆ -0.028282 ┆ 0.492828  ┆ … ┆ -0.15056  ┆ 0.169173  ┆ -0.429713 ┆ -0.90952 │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 9        │\n",
       "│ -0.27464  ┆ -0.599864 ┆ 0.099686  ┆ 0.458822  ┆ … ┆ -0.314905 ┆ 0.112915  ┆ -0.421913 ┆ -0.87439 │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 9        │\n",
       "│ -0.214852 ┆ -0.164345 ┆ 0.041571  ┆ -0.13297  ┆ … ┆ -0.191209 ┆ -0.207123 ┆ -0.089662 ┆ null     │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "computing_returns(tic_sym, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the general loop, that takes each key-value pair from df_dict_scores, applies computing_returns() to it, then verticaly stackes the result with orig df and stores it in the new dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "AEE\n",
      "AKAM\n",
      "ALGN\n",
      "AME\n",
      "AMT\n",
      "AMZN\n",
      "ANSS\n",
      "ARE\n",
      "AXON\n",
      "BAX\n",
      "BBWI\n",
      "BBY\n",
      "BDX\n",
      "BEN\n",
      "BF-B\n",
      "BIIB\n",
      "BIO\n",
      "BK\n",
      "BKNG\n",
      "BKR\n",
      "BLDR\n",
      "BLK\n",
      "BMY\n",
      "BR\n",
      "BRK-B\n",
      "BRO\n",
      "BSX\n",
      "BX\n",
      "BXP\n",
      "C\n",
      "CB\n",
      "CBOE\n",
      "CBRE\n",
      "CCI\n",
      "CCL\n",
      "CDNS\n",
      "CDW\n",
      "CE\n",
      "CF\n",
      "CFG\n",
      "CHD\n",
      "CHRW\n",
      "CHTR\n",
      "CI\n",
      "CINF\n",
      "CL\n",
      "CLX\n",
      "CME\n",
      "CMG\n",
      "CMI\n",
      "CMS\n",
      "CNC\n",
      "CNP\n",
      "COF\n",
      "COO\n",
      "COP\n",
      "COR\n",
      "COST\n",
      "CPB\n",
      "CPRT\n",
      "CPT\n",
      "CRL\n",
      "CRM\n",
      "CSCO\n",
      "CSGP\n",
      "CSX\n",
      "CTLT\n",
      "CTSH\n",
      "CVS\n",
      "CVX\n",
      "CZR\n",
      "D\n",
      "DD\n",
      "DE\n",
      "DECK\n",
      "DFS\n",
      "DG\n",
      "DGX\n",
      "DHI\n",
      "DHR\n",
      "DIS\n",
      "DLR\n",
      "DLTR\n",
      "DOC\n",
      "DOV\n",
      "DOW\n",
      "DPZ\n",
      "DRI\n",
      "DTE\n",
      "DUK\n",
      "DVN\n",
      "DXCM\n",
      "EBAY\n",
      "ECL\n",
      "ED\n",
      "EFX\n",
      "EG\n",
      "EIX\n",
      "EL\n",
      "EMN\n",
      "EMR\n",
      "ENPH\n",
      "EOG\n",
      "EQIX\n",
      "EQR\n",
      "EQT\n",
      "ES\n",
      "ESS\n",
      "ETN\n",
      "ETR\n",
      "ETSY\n",
      "EVRG\n",
      "EW\n",
      "EXC\n",
      "EXPD\n",
      "EXPE\n",
      "EXR\n",
      "F\n",
      "FCX\n",
      "FDS\n",
      "FDX\n",
      "FE\n",
      "FFIV\n",
      "FI\n",
      "FICO\n",
      "FIS\n",
      "FITB\n",
      "FMC\n",
      "FRT\n",
      "FSLR\n",
      "FTNT\n",
      "FTV\n",
      "GD\n",
      "GE\n",
      "GEHC\n",
      "GEN\n",
      "GILD\n",
      "GIS\n",
      "GL\n",
      "GLW\n",
      "GM\n",
      "GNRC\n",
      "GOOGL\n",
      "GPC\n",
      "GPN\n",
      "GRMN\n",
      "GS\n",
      "GWW\n",
      "HD\n",
      "HES\n",
      "HIG\n",
      "HII\n",
      "HLT\n",
      "HOLX\n",
      "HPE\n",
      "HPQ\n",
      "HSIC\n",
      "HST\n",
      "HSY\n",
      "HUBB\n",
      "HUM\n",
      "HWM\n",
      "IBM\n",
      "ICE\n",
      "IDXX\n",
      "IEX\n",
      "IFF\n",
      "ILMN\n",
      "INCY\n",
      "INTC\n",
      "INTU\n",
      "INVH\n",
      "IP\n",
      "IPG\n",
      "IQV\n",
      "IR\n",
      "IRM\n",
      "ISRG\n",
      "IT\n",
      "ITW\n",
      "IVZ\n",
      "J\n",
      "JBHT\n",
      "JBL\n",
      "JCI\n",
      "JKHY\n",
      "JNJ\n",
      "JNPR\n",
      "JPM\n",
      "K\n",
      "KDP\n",
      "KEY\n",
      "KEYS\n",
      "KHC\n",
      "KIM\n",
      "KMB\n",
      "KMI\n",
      "KMX\n",
      "KO\n",
      "KR\n",
      "KVUE\n",
      "L\n",
      "LDOS\n",
      "LEN\n",
      "LH\n",
      "LHX\n",
      "LIN\n",
      "LKQ\n",
      "LLY\n",
      "LMT\n",
      "LNT\n",
      "LOW\n",
      "LRCX\n",
      "LULU\n",
      "LUV\n",
      "LVS\n",
      "LW\n",
      "LYB\n",
      "LYV\n",
      "MAR\n",
      "MCD\n",
      "MCHP\n",
      "MCK\n",
      "MCO\n",
      "MDLZ\n",
      "MDT\n",
      "MET\n",
      "MGM\n",
      "MHK\n",
      "MKC\n",
      "MKTX\n",
      "MLM\n",
      "MMC\n",
      "MMM\n",
      "MNST\n",
      "MO\n",
      "MOH\n",
      "MOS\n",
      "MPC\n",
      "MRK\n",
      "MRO\n",
      "MS\n",
      "MSCI\n",
      "MSFT\n",
      "MSI\n",
      "MTB\n",
      "MTCH\n",
      "MTD\n",
      "MU\n",
      "NCLH\n",
      "NDSN\n",
      "NEE\n",
      "NEM\n",
      "NFLX\n",
      "NI\n",
      "NKE\n",
      "NOC\n",
      "NOW\n",
      "NRG\n",
      "NSC\n",
      "NTAP\n",
      "NTRS\n",
      "NUE\n",
      "NVDA\n",
      "NVR\n",
      "NXPI\n",
      "O\n",
      "ODFL\n",
      "OKE\n",
      "OMC\n",
      "ON\n",
      "ORCL\n",
      "OTIS\n",
      "OXY\n",
      "PCG\n",
      "PEP\n",
      "PFG\n",
      "PG\n",
      "PGR\n",
      "PH\n",
      "PHM\n",
      "PKG\n",
      "PLD\n",
      "PM\n",
      "PNC\n",
      "PNR\n",
      "PNW\n",
      "PODD\n",
      "POOL\n",
      "PPG\n",
      "PPL\n",
      "PRU\n",
      "PSX\n",
      "PTC\n",
      "PWR\n",
      "PYPL\n",
      "QCOM\n",
      "QRVO\n",
      "RCL\n",
      "RF\n",
      "RHI\n",
      "RJF\n",
      "RL\n",
      "RMD\n",
      "ROK\n",
      "ROL\n",
      "ROP\n",
      "ROST\n",
      "RSG\n",
      "RTX\n",
      "RVTY\n",
      "SBAC\n",
      "SBUX\n",
      "SCHW\n",
      "SHW\n",
      "SJM\n",
      "SLB\n",
      "SMCI\n",
      "SNPS\n",
      "SO\n",
      "SPG\n",
      "SRE\n",
      "STE\n",
      "STLD\n",
      "STT\n",
      "STX\n",
      "STZ\n",
      "SWK\n",
      "SWKS\n",
      "SYF\n",
      "SYK\n",
      "SYY\n",
      "T\n",
      "TDG\n",
      "TDY\n",
      "TECH\n",
      "TER\n",
      "TFC\n",
      "TFX\n",
      "TGT\n",
      "TJX\n",
      "TMO\n",
      "TMUS\n",
      "TPR\n",
      "TRGP\n",
      "TRMB\n",
      "TROW\n",
      "TRV\n",
      "TSCO\n",
      "TSN\n",
      "TT\n",
      "TTWO\n",
      "TXN\n",
      "TXT\n",
      "TYL\n",
      "UAL\n",
      "UBER\n",
      "UDR\n",
      "UHS\n",
      "UNH\n",
      "UNP\n",
      "UPS\n",
      "URI\n",
      "USB\n",
      "V\n",
      "VICI\n",
      "VLO\n",
      "VLTO\n",
      "VMC\n",
      "VRSK\n",
      "VRSN\n",
      "VST\n",
      "VTR\n",
      "VTRS\n",
      "VZ\n",
      "WAT\n",
      "WBD\n",
      "WDC\n",
      "WEC\n",
      "WFC\n",
      "WM\n",
      "WMB\n",
      "WMT\n",
      "WRB\n",
      "WRK\n",
      "WST\n",
      "WTW\n",
      "WY\n",
      "XOM\n",
      "XYL\n",
      "YUM\n",
      "ZBH\n",
      "ZTS\n"
     ]
    }
   ],
   "source": [
    "dict_for_anal = {}\n",
    "row_names = pl.Series(\"row_names\", [\"lm_polarity\", \"lm_raw\", \"hiv4_polarity\", \"hiv4_raw\", \"doc_length\", \"2_day_reterns\",\"3_day_reterns\", \"4_day_reterns\", \"5_day_reterns\", \"6_day_reterns\", \"7_day_reterns\", \"full_quarter_returns\"])\n",
    "\n",
    "for tic_sym, df in df_dict_scores.items():\n",
    "    print(tic_sym)\n",
    "\n",
    "    returns_df = computing_returns(tic_sym, df)\n",
    "    \n",
    "    stacked_df = df.vstack(returns_df)\n",
    "    stacked_df_with_indx = stacked_df.hstack([row_names])\n",
    "    \n",
    "    dict_for_anal[tic_sym] = stacked_df_with_indx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (12, 21)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>2019-03-13</th><th>2019-06-06</th><th>2019-10-11</th><th>2019-12-23</th><th>2020-03-12</th><th>2020-06-04</th><th>2020-10-07</th><th>2020-12-16</th><th>2021-03-10</th><th>2021-06-03</th><th>2021-10-06</th><th>2021-12-22</th><th>2022-03-10</th><th>2022-06-02</th><th>2022-10-05</th><th>2022-12-29</th><th>2023-03-09</th><th>2023-06-01</th><th>2023-10-11</th><th>2023-12-20</th><th>row_names</th></tr><tr><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>str</td></tr></thead><tbody><tr><td>-0.206751</td><td>-0.184314</td><td>-0.313433</td><td>-0.34413</td><td>-0.304348</td><td>-0.378747</td><td>-0.360294</td><td>-0.362712</td><td>-0.396721</td><td>-0.358255</td><td>-0.380385</td><td>-0.35082</td><td>-0.309211</td><td>-0.339394</td><td>-0.358279</td><td>-0.372671</td><td>-0.378049</td><td>-0.368421</td><td>-0.365762</td><td>-0.340351</td><td>&quot;lm_polarity&quot;</td></tr><tr><td>-49.0</td><td>-47.0</td><td>-315.0</td><td>-85.0</td><td>-77.0</td><td>-139.0</td><td>-392.0</td><td>-107.0</td><td>-121.0</td><td>-115.0</td><td>-415.0</td><td>-107.0</td><td>-94.0</td><td>-112.0</td><td>-383.0</td><td>-120.0</td><td>-124.0</td><td>-126.0</td><td>-391.0</td><td>-97.0</td><td>&quot;lm_raw&quot;</td></tr><tr><td>0.486711</td><td>0.447115</td><td>0.429211</td><td>0.478873</td><td>0.454098</td><td>0.401434</td><td>0.408528</td><td>0.398825</td><td>0.381762</td><td>0.350338</td><td>0.411323</td><td>0.408146</td><td>0.365539</td><td>0.337433</td><td>0.407461</td><td>0.382573</td><td>0.347928</td><td>0.332814</td><td>0.409683</td><td>0.430544</td><td>&quot;hiv4_polarity&quot;</td></tr><tr><td>586.0</td><td>558.0</td><td>1725.0</td><td>544.0</td><td>554.0</td><td>672.0</td><td>1782.0</td><td>475.0</td><td>494.0</td><td>467.0</td><td>1751.0</td><td>491.0</td><td>454.0</td><td>439.0</td><td>1682.0</td><td>461.0</td><td>445.0</td><td>427.0</td><td>1667.0</td><td>499.0</td><td>&quot;hiv4_raw&quot;</td></tr><tr><td>8407.0</td><td>8594.0</td><td>23602.0</td><td>7720.0</td><td>8170.0</td><td>11161.0</td><td>25803.0</td><td>8219.0</td><td>8994.0</td><td>9249.0</td><td>25592.0</td><td>8117.0</td><td>8374.0</td><td>8776.0</td><td>24367.0</td><td>8030.0</td><td>8634.0</td><td>8683.0</td><td>24150.0</td><td>7741.0</td><td>&quot;doc_length&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>-0.016934</td><td>0.486502</td><td>-0.25266</td><td>-0.168993</td><td>3.412324</td><td>-1.169854</td><td>0.140992</td><td>-0.487915</td><td>0.139887</td><td>-0.210348</td><td>0.068187</td><td>0.220157</td><td>0.814454</td><td>0.274492</td><td>0.201693</td><td>-0.285074</td><td>0.456089</td><td>-0.357982</td><td>0.436089</td><td>0.176791</td><td>&quot;4_day_reterns&quot;</td></tr><tr><td>0.011902</td><td>0.374867</td><td>0.035754</td><td>0.073497</td><td>3.941941</td><td>-0.325292</td><td>0.470356</td><td>-0.454028</td><td>0.00678</td><td>-0.143981</td><td>0.029709</td><td>0.266868</td><td>0.338515</td><td>0.248982</td><td>0.575443</td><td>0.232838</td><td>0.49423</td><td>-0.285083</td><td>0.363469</td><td>0.182819</td><td>&quot;5_day_reterns&quot;</td></tr><tr><td>0.054192</td><td>0.462871</td><td>0.087739</td><td>-0.144229</td><td>2.893324</td><td>-0.221544</td><td>0.398744</td><td>-0.427807</td><td>0.013731</td><td>-0.019398</td><td>-0.13982</td><td>0.10353</td><td>0.344388</td><td>0.640765</td><td>0.233862</td><td>0.53713</td><td>0.220959</td><td>-0.195569</td><td>0.433768</td><td>0.04174</td><td>&quot;6_day_reterns&quot;</td></tr><tr><td>0.107134</td><td>0.447042</td><td>-0.060114</td><td>-0.236795</td><td>2.436417</td><td>-0.093365</td><td>0.333985</td><td>-0.321355</td><td>0.032244</td><td>-0.15059</td><td>-0.103206</td><td>0.122175</td><td>0.306305</td><td>0.559532</td><td>-0.035964</td><td>0.362387</td><td>0.3053</td><td>-0.204902</td><td>0.34615</td><td>0.030871</td><td>&quot;7_day_reterns&quot;</td></tr><tr><td>0.086941</td><td>0.176383</td><td>-0.194409</td><td>0.254507</td><td>-0.123701</td><td>0.085499</td><td>-0.068234</td><td>-0.332169</td><td>0.182641</td><td>0.162029</td><td>0.285065</td><td>0.087101</td><td>-0.138859</td><td>0.15071</td><td>-0.111074</td><td>0.044668</td><td>0.001541</td><td>0.073867</td><td>0.204752</td><td>null</td><td>&quot;full_quarter_r…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (12, 21)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ 2019-03-1 ┆ 2019-06-0 ┆ 2019-10-1 ┆ 2019-12-2 ┆ … ┆ 2023-06-0 ┆ 2023-10-1 ┆ 2023-12-2 ┆ row_name │\n",
       "│ 3         ┆ 6         ┆ 1         ┆ 3         ┆   ┆ 1         ┆ 1         ┆ 0         ┆ s        │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│ f64       ┆ f64       ┆ f64       ┆ f64       ┆   ┆ f64       ┆ f64       ┆ f64       ┆ str      │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ -0.206751 ┆ -0.184314 ┆ -0.313433 ┆ -0.34413  ┆ … ┆ -0.368421 ┆ -0.365762 ┆ -0.340351 ┆ lm_polar │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ ity      │\n",
       "│ -49.0     ┆ -47.0     ┆ -315.0    ┆ -85.0     ┆ … ┆ -126.0    ┆ -391.0    ┆ -97.0     ┆ lm_raw   │\n",
       "│ 0.486711  ┆ 0.447115  ┆ 0.429211  ┆ 0.478873  ┆ … ┆ 0.332814  ┆ 0.409683  ┆ 0.430544  ┆ hiv4_pol │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ arity    │\n",
       "│ 586.0     ┆ 558.0     ┆ 1725.0    ┆ 544.0     ┆ … ┆ 427.0     ┆ 1667.0    ┆ 499.0     ┆ hiv4_raw │\n",
       "│ 8407.0    ┆ 8594.0    ┆ 23602.0   ┆ 7720.0    ┆ … ┆ 8683.0    ┆ 24150.0   ┆ 7741.0    ┆ doc_leng │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ th       │\n",
       "│ …         ┆ …         ┆ …         ┆ …         ┆ … ┆ …         ┆ …         ┆ …         ┆ …        │\n",
       "│ -0.016934 ┆ 0.486502  ┆ -0.25266  ┆ -0.168993 ┆ … ┆ -0.357982 ┆ 0.436089  ┆ 0.176791  ┆ 4_day_re │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ terns    │\n",
       "│ 0.011902  ┆ 0.374867  ┆ 0.035754  ┆ 0.073497  ┆ … ┆ -0.285083 ┆ 0.363469  ┆ 0.182819  ┆ 5_day_re │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ terns    │\n",
       "│ 0.054192  ┆ 0.462871  ┆ 0.087739  ┆ -0.144229 ┆ … ┆ -0.195569 ┆ 0.433768  ┆ 0.04174   ┆ 6_day_re │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ terns    │\n",
       "│ 0.107134  ┆ 0.447042  ┆ -0.060114 ┆ -0.236795 ┆ … ┆ -0.204902 ┆ 0.34615   ┆ 0.030871  ┆ 7_day_re │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ terns    │\n",
       "│ 0.086941  ┆ 0.176383  ┆ -0.194409 ┆ 0.254507  ┆ … ┆ 0.073867  ┆ 0.204752  ┆ null      ┆ full_qua │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ rter_ret │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ urns     │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_for_anal[\"COST\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This func takes as input key-value pair (company name and dataframe with sentiment scores and returns), regress each retern (2_days, 3_days, etc) on weightes sentiment score ans raw sentiment score. Then it collects the slopes (beta-coefficient) of returns regressed on raw score and on weighted score in the separate polars series (in the loop they will be staked in dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_quarter_dummy(company_df_pd):\n",
    "    \n",
    "    dates = pd.to_datetime(company_df_pd.columns)\n",
    "   \n",
    "    date_series = pd.Series(dates.quarter, index=dates)\n",
    "   \n",
    "    dummies = pd.get_dummies(date_series, prefix=\"Q\")\n",
    "    dummies.index = dummies.index.strftime('%Y-%m-%d')\n",
    "    \n",
    "    all_quarters = [\"Q_1\", \"Q_2\", \"Q_3\", \"Q_4\"]\n",
    "    dummies = dummies.reindex(columns=all_quarters, fill_value=False)\n",
    "   \n",
    "    dummies = dummies.drop(columns=[\"Q_4\"])\n",
    "    \n",
    "    dummies = dummies.transpose()\n",
    "    df_wit_dum = pd.concat([company_df_pd, dummies])\n",
    "    \n",
    "    df_wit_dum = df_wit_dum.transpose()\n",
    "   \n",
    "    for col in df_wit_dum.columns:\n",
    "        df_wit_dum[col] = pd.to_numeric(df_wit_dum[col])\n",
    "\n",
    "    boolean_cols = ['Q_1', 'Q_2', 'Q_3']\n",
    "    df_wit_dum[boolean_cols] = df_wit_dum[boolean_cols].astype(int)\n",
    "\n",
    "    return df_wit_dum\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "company_df = dict_for_anal[\"VLTO\"] #COST YUM\n",
    "\n",
    "company_df_woi = company_df.select(pl.exclude(\"row_names\"))\n",
    "\n",
    "company_df_woi = company_df_woi.to_pandas()\n",
    "\n",
    "df_wit_dum = add_quarter_dummy(company_df_woi)\n",
    "print(df_wit_dum.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_regression(y, x):\n",
    "\n",
    "    x = sm.add_constant(x)\n",
    "    model = sm.OLS(y, x, missing='drop').fit()\n",
    "    \n",
    "    slope = model.params.iloc[1]\n",
    "    #print(model.summary())\n",
    "    \n",
    "    return slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (12, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>2023-10-26</th><th>row_names</th></tr><tr><td>f64</td><td>str</td></tr></thead><tbody><tr><td>0.064579</td><td>&quot;lm_polarity&quot;</td></tr><tr><td>33.0</td><td>&quot;lm_raw&quot;</td></tr><tr><td>0.495394</td><td>&quot;hiv4_polarity&quot;</td></tr><tr><td>1237.0</td><td>&quot;hiv4_raw&quot;</td></tr><tr><td>14620.0</td><td>&quot;doc_length&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>0.538392</td><td>&quot;4_day_reterns&quot;</td></tr><tr><td>0.061637</td><td>&quot;5_day_reterns&quot;</td></tr><tr><td>0.408705</td><td>&quot;6_day_reterns&quot;</td></tr><tr><td>0.157099</td><td>&quot;7_day_reterns&quot;</td></tr><tr><td>null</td><td>&quot;full_quarter_r…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (12, 2)\n",
       "┌────────────┬──────────────────────┐\n",
       "│ 2023-10-26 ┆ row_names            │\n",
       "│ ---        ┆ ---                  │\n",
       "│ f64        ┆ str                  │\n",
       "╞════════════╪══════════════════════╡\n",
       "│ 0.064579   ┆ lm_polarity          │\n",
       "│ 33.0       ┆ lm_raw               │\n",
       "│ 0.495394   ┆ hiv4_polarity        │\n",
       "│ 1237.0     ┆ hiv4_raw             │\n",
       "│ 14620.0    ┆ doc_length           │\n",
       "│ …          ┆ …                    │\n",
       "│ 0.538392   ┆ 4_day_reterns        │\n",
       "│ 0.061637   ┆ 5_day_reterns        │\n",
       "│ 0.408705   ┆ 6_day_reterns        │\n",
       "│ 0.157099   ┆ 7_day_reterns        │\n",
       "│ null       ┆ full_quarter_returns │\n",
       "└────────────┴──────────────────────┘"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_for_anal[\"VLTO\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_slopes(df_wit_dum, X_names, company_name=\"total_df\"):\n",
    "\n",
    "    # x in range(0, 4) represents set of independent variables; 4th column represents control variable for document length; -3, -2, -1 columns represent dummy variables for quarters\n",
    "    X = [df_wit_dum.iloc[:, [x, 4, -3, -2, -1]] for x in range(0, 4)]\n",
    "\n",
    "    Y = [df_wit_dum.iloc[:, [y]] for y in range(5, 12)]\n",
    "\n",
    "    slopes_dict = {}\n",
    "\n",
    "    for i, x in enumerate(X):\n",
    "\n",
    "        name_of_score = X_names[i][0].split()[0]\n",
    "        slopes_name = f'{name_of_score}_slopes'\n",
    "        \n",
    "        slopes = []\n",
    "        for y in Y:\n",
    "            slope = fit_regression(y, x)\n",
    "            slopes.append(slope)\n",
    "\n",
    "        slopes_dict[slopes_name] = pl.Series(company_name, slopes)\n",
    "    \n",
    "    return slopes_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the general loop that takes dict_for_anal() whith scores and returns and for each company in the dict it calculates two series: first one contain regression slopes for weighted scores and second one for raw scores. Serieses stacked in the separete dataframes (for raw and for weighted scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_all_slopes(dict_for_anal):\n",
    "\n",
    "    slopes_df_dict = {\n",
    "        \"lm_polarity_slopes_df\" : pl.DataFrame(),\n",
    "        \"lm_raw_slopes_df\" : pl.DataFrame(),\n",
    "        \"hiv4_polarity_slopes_df\" : pl.DataFrame(),\n",
    "        \"hiv4_raw_slopes_df\" : pl.DataFrame()\n",
    "    }\n",
    "    \n",
    "    for company_name, company_df in dict_for_anal.items(): \n",
    "\n",
    "        X_names = [company_df.select(pl.col(\"row_names\")).row(x) for x in range(0, 4)]\n",
    "\n",
    "        company_df_woi = company_df.select(pl.exclude(\"row_names\"))\n",
    "\n",
    "        company_df_woi = company_df_woi.to_pandas()\n",
    "        print(company_name)\n",
    "\n",
    "        df_wit_dum = add_quarter_dummy(company_df_woi)\n",
    "        if df_wit_dum.shape[0] > 6:\n",
    "\n",
    "            slopes_dict = regression_slopes(df_wit_dum, X_names, company_name)\n",
    "    \n",
    "            for x in X_names:\n",
    "                \n",
    "                name_of_score = x[0].split()[0]\n",
    "                slopes_name = f'{name_of_score}_slopes'\n",
    "                \n",
    "                df_name = f\"{name_of_score}_slopes_df\"\n",
    "                \n",
    "                slopes_df_dict[df_name] = slopes_df_dict[df_name].hstack([slopes_dict[slopes_name]])\n",
    "\n",
    "    return slopes_df_dict\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "AEE\n",
      "AKAM\n",
      "ALGN\n",
      "AME\n",
      "AMT\n",
      "AMZN\n",
      "ANSS\n",
      "ARE\n",
      "AXON\n",
      "BAX\n",
      "BBWI\n",
      "BBY\n",
      "BDX\n",
      "BEN\n",
      "BF-B\n",
      "BIIB\n",
      "BIO\n",
      "BK\n",
      "BKNG\n",
      "BKR\n",
      "BLDR\n",
      "BLK\n",
      "BMY\n",
      "BR\n",
      "BRK-B\n",
      "BRO\n",
      "BSX\n",
      "BX\n",
      "BXP\n",
      "C\n",
      "CB\n",
      "CBOE\n",
      "CBRE\n",
      "CCI\n",
      "CCL\n",
      "CDNS\n",
      "CDW\n",
      "CE\n",
      "CF\n",
      "CFG\n",
      "CHD\n",
      "CHRW\n",
      "CHTR\n",
      "CI\n",
      "CINF\n",
      "CL\n",
      "CLX\n",
      "CME\n",
      "CMG\n",
      "CMI\n",
      "CMS\n",
      "CNC\n",
      "CNP\n",
      "COF\n",
      "COO\n",
      "COP\n",
      "COR\n",
      "COST\n",
      "CPB\n",
      "CPRT\n",
      "CPT\n",
      "CRL\n",
      "CRM\n",
      "CSCO\n",
      "CSGP\n",
      "CSX\n",
      "CTLT\n",
      "CTSH\n",
      "CVS\n",
      "CVX\n",
      "CZR\n",
      "D\n",
      "DD\n",
      "DE\n",
      "DECK\n",
      "DFS\n",
      "DG\n",
      "DGX\n",
      "DHI\n",
      "DHR\n",
      "DIS\n",
      "DLR\n",
      "DLTR\n",
      "DOC\n",
      "DOV\n",
      "DOW\n",
      "DPZ\n",
      "DRI\n",
      "DTE\n",
      "DUK\n",
      "DVN\n",
      "DXCM\n",
      "EBAY\n",
      "ECL\n",
      "ED\n",
      "EFX\n",
      "EG\n",
      "EIX\n",
      "EL\n",
      "EMN\n",
      "EMR\n",
      "ENPH\n",
      "EOG\n",
      "EQIX\n",
      "EQR\n",
      "EQT\n",
      "ES\n",
      "ESS\n",
      "ETN\n",
      "ETR\n",
      "ETSY\n",
      "EVRG\n",
      "EW\n",
      "EXC\n",
      "EXPD\n",
      "EXPE\n",
      "EXR\n",
      "F\n",
      "FCX\n",
      "FDS\n",
      "FDX\n",
      "FE\n",
      "FFIV\n",
      "FI\n",
      "FICO\n",
      "FIS\n",
      "FITB\n",
      "FMC\n",
      "FRT\n",
      "FSLR\n",
      "FTNT\n",
      "FTV\n",
      "GD\n",
      "GE\n",
      "GEHC\n",
      "GEN\n",
      "GILD\n",
      "GIS\n",
      "GL\n",
      "GLW\n",
      "GM\n",
      "GNRC\n",
      "GOOGL\n",
      "GPC\n",
      "GPN\n",
      "GRMN\n",
      "GS\n",
      "GWW\n",
      "HD\n",
      "HES\n",
      "HIG\n",
      "HII\n",
      "HLT\n",
      "HOLX\n",
      "HPE\n",
      "HPQ\n",
      "HSIC\n",
      "HST\n",
      "HSY\n",
      "HUBB\n",
      "HUM\n",
      "HWM\n",
      "IBM\n",
      "ICE\n",
      "IDXX\n",
      "IEX\n",
      "IFF\n",
      "ILMN\n",
      "INCY\n",
      "INTC\n",
      "INTU\n",
      "INVH\n",
      "IP\n",
      "IPG\n",
      "IQV\n",
      "IR\n",
      "IRM\n",
      "ISRG\n",
      "IT\n",
      "ITW\n",
      "IVZ\n",
      "J\n",
      "JBHT\n",
      "JBL\n",
      "JCI\n",
      "JKHY\n",
      "JNJ\n",
      "JNPR\n",
      "JPM\n",
      "K\n",
      "KDP\n",
      "KEY\n",
      "KEYS\n",
      "KHC\n",
      "KIM\n",
      "KMB\n",
      "KMI\n",
      "KMX\n",
      "KO\n",
      "KR\n",
      "KVUE\n",
      "L\n",
      "LDOS\n",
      "LEN\n",
      "LH\n",
      "LHX\n",
      "LIN\n",
      "LKQ\n",
      "LLY\n",
      "LMT\n",
      "LNT\n",
      "LOW\n",
      "LRCX\n",
      "LULU\n",
      "LUV\n",
      "LVS\n",
      "LW\n",
      "LYB\n",
      "LYV\n",
      "MAR\n",
      "MCD\n",
      "MCHP\n",
      "MCK\n",
      "MCO\n",
      "MDLZ\n",
      "MDT\n",
      "MET\n",
      "MGM\n",
      "MHK\n",
      "MKC\n",
      "MKTX\n",
      "MLM\n",
      "MMC\n",
      "MMM\n",
      "MNST\n",
      "MO\n",
      "MOH\n",
      "MOS\n",
      "MPC\n",
      "MRK\n",
      "MRO\n",
      "MS\n",
      "MSCI\n",
      "MSFT\n",
      "MSI\n",
      "MTB\n",
      "MTCH\n",
      "MTD\n",
      "MU\n",
      "NCLH\n",
      "NDSN\n",
      "NEE\n",
      "NEM\n",
      "NFLX\n",
      "NI\n",
      "NKE\n",
      "NOC\n",
      "NOW\n",
      "NRG\n",
      "NSC\n",
      "NTAP\n",
      "NTRS\n",
      "NUE\n",
      "NVDA\n",
      "NVR\n",
      "NXPI\n",
      "O\n",
      "ODFL\n",
      "OKE\n",
      "OMC\n",
      "ON\n",
      "ORCL\n",
      "OTIS\n",
      "OXY\n",
      "PCG\n",
      "PEP\n",
      "PFG\n",
      "PG\n",
      "PGR\n",
      "PH\n",
      "PHM\n",
      "PKG\n",
      "PLD\n",
      "PM\n",
      "PNC\n",
      "PNR\n",
      "PNW\n",
      "PODD\n",
      "POOL\n",
      "PPG\n",
      "PPL\n",
      "PRU\n",
      "PSX\n",
      "PTC\n",
      "PWR\n",
      "PYPL\n",
      "QCOM\n",
      "QRVO\n",
      "RCL\n",
      "RF\n",
      "RHI\n",
      "RJF\n",
      "RL\n",
      "RMD\n",
      "ROK\n",
      "ROL\n",
      "ROP\n",
      "ROST\n",
      "RSG\n",
      "RTX\n",
      "RVTY\n",
      "SBAC\n",
      "SBUX\n",
      "SCHW\n",
      "SHW\n",
      "SJM\n",
      "SLB\n",
      "SMCI\n",
      "SNPS\n",
      "SO\n",
      "SPG\n",
      "SRE\n",
      "STE\n",
      "STLD\n",
      "STT\n",
      "STX\n",
      "STZ\n",
      "SWK\n",
      "SWKS\n",
      "SYF\n",
      "SYK\n",
      "SYY\n",
      "T\n",
      "TDG\n",
      "TDY\n",
      "TECH\n",
      "TER\n",
      "TFC\n",
      "TFX\n",
      "TGT\n",
      "TJX\n",
      "TMO\n",
      "TMUS\n",
      "TPR\n",
      "TRGP\n",
      "TRMB\n",
      "TROW\n",
      "TRV\n",
      "TSCO\n",
      "TSN\n",
      "TT\n",
      "TTWO\n",
      "TXN\n",
      "TXT\n",
      "TYL\n",
      "UAL\n",
      "UBER\n",
      "UDR\n",
      "UHS\n",
      "UNH\n",
      "UNP\n",
      "UPS\n",
      "URI\n",
      "USB\n",
      "V\n",
      "VICI\n",
      "VLO\n",
      "VLTO\n",
      "VMC\n",
      "VRSK\n",
      "VRSN\n",
      "VST\n",
      "VTR\n",
      "VTRS\n",
      "VZ\n",
      "WAT\n",
      "WBD\n",
      "WDC\n",
      "WEC\n",
      "WFC\n",
      "WM\n",
      "WMB\n",
      "WMT\n",
      "WRB\n",
      "WRK\n",
      "WST\n",
      "WTW\n",
      "WY\n",
      "XOM\n",
      "XYL\n",
      "YUM\n",
      "ZBH\n",
      "ZTS\n"
     ]
    }
   ],
   "source": [
    "slopes_df_dict = compute_all_slopes(dict_for_anal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an output from previous functions we have dataframes with regression slopes of different returns on raw, weighted scores and Loughran-McDonald and Harvard dictionaries. Each col of these dfs contain regression slopes for particular company. First row contain slope for 2_days return, second row contain slope for 3_days return, etc.  I have decided to check what is the proportion of positive regression slopes for each return timeframe (2_days, 3_days, etc). For that purpose i will transpose each of these dfs, apply condition > 0, then verticaly sum boolean values and obtain the prorortion of positive slopes for each time frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_efficiency_metrics(slopes_df):\n",
    "\n",
    "    df_tranposed = slopes_df.transpose()\n",
    "\n",
    "    res = df_tranposed.select(pl.all() > 0).sum()\n",
    "    total_num_of_slopes = slopes_df.shape[1]\n",
    "\n",
    "    positive_slopes = [res.select(pl.col(res.columns[x]).gather(0)).item() for x in range(slopes_df.shape[0])]\n",
    "\n",
    "    for counter, x in enumerate(positive_slopes):\n",
    "        print(f'Prorortion of positive {counter + 2}_day returns: {x/total_num_of_slopes}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This loop apply calc_efficiency_metrics function to each item of slopes_df_dict where each item is a dataframe which regression slopes for each regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Metrics for: lm_polarity_slopes_df\n",
      "Prorortion of positive 2_day returns: 0.4859335038363171\n",
      "Prorortion of positive 3_day returns: 0.5012787723785166\n",
      "Prorortion of positive 4_day returns: 0.5038363171355499\n",
      "Prorortion of positive 5_day returns: 0.5294117647058824\n",
      "Prorortion of positive 6_day returns: 0.4859335038363171\n",
      "Prorortion of positive 7_day returns: 0.4782608695652174\n",
      "Prorortion of positive 8_day returns: 0.4629156010230179\n",
      "\n",
      "\n",
      "Metrics for: lm_raw_slopes_df\n",
      "Prorortion of positive 2_day returns: 0.4782608695652174\n",
      "Prorortion of positive 3_day returns: 0.47570332480818417\n",
      "Prorortion of positive 4_day returns: 0.4936061381074169\n",
      "Prorortion of positive 5_day returns: 0.4629156010230179\n",
      "Prorortion of positive 6_day returns: 0.46547314578005117\n",
      "Prorortion of positive 7_day returns: 0.4782608695652174\n",
      "Prorortion of positive 8_day returns: 0.46035805626598464\n",
      "\n",
      "\n",
      "Metrics for: hiv4_polarity_slopes_df\n",
      "Prorortion of positive 2_day returns: 0.4833759590792839\n",
      "Prorortion of positive 3_day returns: 0.4833759590792839\n",
      "Prorortion of positive 4_day returns: 0.5038363171355499\n",
      "Prorortion of positive 5_day returns: 0.4936061381074169\n",
      "Prorortion of positive 6_day returns: 0.4884910485933504\n",
      "Prorortion of positive 7_day returns: 0.5012787723785166\n",
      "Prorortion of positive 8_day returns: 0.42455242966751916\n",
      "\n",
      "\n",
      "Metrics for: hiv4_raw_slopes_df\n",
      "Prorortion of positive 2_day returns: 0.5012787723785166\n",
      "Prorortion of positive 3_day returns: 0.5038363171355499\n",
      "Prorortion of positive 4_day returns: 0.5294117647058824\n",
      "Prorortion of positive 5_day returns: 0.5345268542199488\n",
      "Prorortion of positive 6_day returns: 0.5447570332480819\n",
      "Prorortion of positive 7_day returns: 0.5166240409207161\n",
      "Prorortion of positive 8_day returns: 0.4731457800511509\n"
     ]
    }
   ],
   "source": [
    "for key, slopes_df in slopes_df_dict.items():\n",
    "    print(\"\\n\")\n",
    "    print(f'Metrics for: {key}')\n",
    "    calc_efficiency_metrics(slopes_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positive slopes means that sentiment scores and returns mooves in the same direction (hense, they are working as predictors of stock price movement). As the result of this preliminary analisis we can say that sentiment scores of quarterly reports are not very good predictors of stock movments. Positive proportion of this slopes are close to 0.5, which means that on average in our sample there are 50/50 chance that scores and returns are mooving in the same direction.\n",
    "\n",
    "As we can see that, despite visual conclusion that weighted scores are more \"smooth\", they barely outperform raw scores, but at least they are not worse, meaning that at each time frame (except 5_days) the proportion of positive regression slopes of weighted scores => proportion of positive regression slopes of raw scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This func stackes all data in one df, and calculate the single slope for each time frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_signl_slope(dict_for_anal):\n",
    "\n",
    "    df_list = []\n",
    "    \n",
    "    for company_name in dict_for_anal:\n",
    "\n",
    "\n",
    "        X_names = [dict_for_anal[company_name].select(pl.col(\"row_names\")).row(x) for x in range(0, 4)] \n",
    "    \n",
    "        company_df_woi = dict_for_anal[company_name].select(pl.exclude(\"row_names\"))\n",
    "        company_df_pd = company_df_woi.to_pandas(use_pyarrow_extension_array=True)\n",
    "\n",
    "        df_wit_dum = add_quarter_dummy(company_df_pd)\n",
    "\n",
    "        df_list.append(df_wit_dum)\n",
    "        \n",
    "\n",
    "    total_df = pd.concat(df_list, ignore_index=True)\n",
    "    \n",
    "    slopes_dict = regression_slopes(total_df, X_names)\n",
    "\n",
    "    return slopes_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lm_polarity_slopes': shape: (7,)\n",
      "Series: 'total_df' [f64]\n",
      "[\n",
      "\t-0.055154\n",
      "\t-0.08022\n",
      "\t-0.08314\n",
      "\t-0.02476\n",
      "\t-0.034068\n",
      "\t-0.057957\n",
      "\t-0.038509\n",
      "], 'lm_raw_slopes': shape: (7,)\n",
      "Series: 'total_df' [f64]\n",
      "[\n",
      "\t-0.000092\n",
      "\t-0.000089\n",
      "\t-0.00005\n",
      "\t0.000012\n",
      "\t0.000007\n",
      "\t-0.000006\n",
      "\t-0.000015\n",
      "], 'hiv4_polarity_slopes': shape: (7,)\n",
      "Series: 'total_df' [f64]\n",
      "[\n",
      "\t0.110932\n",
      "\t-0.043767\n",
      "\t-0.105612\n",
      "\t0.055902\n",
      "\t0.013775\n",
      "\t0.004987\n",
      "\t-0.095311\n",
      "], 'hiv4_raw_slopes': shape: (7,)\n",
      "Series: 'total_df' [f64]\n",
      "[\n",
      "\t-0.000016\n",
      "\t-0.000027\n",
      "\t-0.000043\n",
      "\t-0.000016\n",
      "\t-0.00001\n",
      "\t-0.000019\n",
      "\t-0.000023\n",
      "]}\n"
     ]
    }
   ],
   "source": [
    "slopes_dict = compute_signl_slope(dict_for_anal)\n",
    "print(slopes_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
