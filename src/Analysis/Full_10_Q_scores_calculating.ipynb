{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import polars.selectors as cs\n",
    "from polars import functions as pf\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: YOU NEED HAVE RENAMED JPMORGAN IN FULL_10_Q_SCORCES MANUALY, SO DONT FORGET TO CHANGE THE NAME IN THE PARSER AND HERE\n",
    "#COMPANY_NAME_LIST = ['Apple%2520Inc.%2520(AAPL)%2520(CIK%25200000320193)', 'MICROSOFT%2520CORP%2520(MSFT)%2520(CIK%25200000789019)', \n",
    "#                     'BigCommerce%2520Holdings%252C%2520Inc.%2520(BIGC)%2520(CIK%25200001626450)', 'ROKU%252C%2520INC%2520(ROKU)%2520(CIK%25200001428439)', \n",
    "#                     'JPMORGAN%2520CHASE%2520(CIK%25200000019617)', 'VISA%2520INC.%2520(V)%2520(CIK%25200001403161)', \n",
    "#                     'Block%252C%2520Inc.%2520(SQ%252C%2520BSQKZ)%2520(CIK%25200001512673)', 'Robinhood%2520Markets%252C%2520Inc.%2520(HOOD)%2520(CIK%25200001783879)', \n",
    "#                     'JOHNSON%252C%252C%2520JOHNSON%2520(JNJ)%2520(CIK%25200000200406)', 'PFIZER%2520INC%2520(PFE)%2520(CIK%25200000078003)', \n",
    "#                     'Moderna%252C%2520Inc.%2520(MRNA)%2520(CIK%25200001682852)', 'Teladoc%2520Health%252C%2520Inc.%2520(TDOC)%2520(CIK%25200001477449)', \n",
    "#                     'EXXON%2520MOBIL%2520CORP%2520(XOM)%2520(CIK%25200000034088)', 'CHEVRON%2520CORP%2520(CVX)%2520(CIK%25200000093410)', \n",
    "#                     'FIRST%2520SOLAR%252C%2520INC.%2520(FSLR)%2520(CIK%25200001274494)', 'PLUG%2520POWER%2520INC%2520(PLUG)%2520(CIK%25200001093691)', \n",
    "#                     'GENERAL%252CELECTRIC%2520CO%2520(GE)%2520(CIK%25200000040545)', '3M%2520CO%2520(MMM)%2520(CIK%25200000066740)', \n",
    "#                     'CATERPILLAR%2520INC%2520(CAT)%2520(CIK%25200000018230)', 'FASTENAL%2520CO%2520(FAST)%2520(CIK%25200000815556)']\n",
    "COMPANY_NAME_LIST = ['Apple%2520Inc.%2520(AAPL)%2520(CIK%25200000320193)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (86_531, 16)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Word</th><th>Seq_num</th><th>Word Count</th><th>Word Proportion</th><th>Average Proportion</th><th>Std Dev</th><th>Doc Count</th><th>Negative</th><th>Positive</th><th>Uncertainty</th><th>Litigious</th><th>Strong_Modal</th><th>Weak_Modal</th><th>Constraining</th><th>Syllables</th><th>Source</th></tr><tr><td>str</td><td>i64</td><td>i64</td><td>f64</td><td>f64</td><td>f64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>str</td></tr></thead><tbody><tr><td>&quot;AARDVARK&quot;</td><td>1</td><td>354</td><td>1.5501e-8</td><td>1.4226e-8</td><td>0.000004</td><td>99</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>2</td><td>&quot;12of12inf&quot;</td></tr><tr><td>&quot;AARDVARKS&quot;</td><td>2</td><td>3</td><td>1.3136e-10</td><td>8.6538e-12</td><td>9.2417e-9</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>2</td><td>&quot;12of12inf&quot;</td></tr><tr><td>&quot;ABACI&quot;</td><td>3</td><td>9</td><td>3.9409e-10</td><td>1.1697e-10</td><td>5.2905e-8</td><td>7</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>3</td><td>&quot;12of12inf&quot;</td></tr><tr><td>&quot;ABACK&quot;</td><td>4</td><td>29</td><td>1.2698e-9</td><td>6.6547e-10</td><td>1.5951e-7</td><td>28</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>2</td><td>&quot;12of12inf&quot;</td></tr><tr><td>&quot;ABACUS&quot;</td><td>5</td><td>8570</td><td>3.7526e-7</td><td>3.8095e-7</td><td>0.000035</td><td>1108</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>3</td><td>&quot;12of12inf&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;ZYGOTE&quot;</td><td>86529</td><td>50</td><td>2.1894e-9</td><td>8.7293e-10</td><td>1.8860e-7</td><td>35</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>2</td><td>&quot;12of12inf&quot;</td></tr><tr><td>&quot;ZYGOTES&quot;</td><td>86530</td><td>1</td><td>4.3788e-11</td><td>1.8095e-11</td><td>1.9324e-8</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>2</td><td>&quot;12of12inf&quot;</td></tr><tr><td>&quot;ZYGOTIC&quot;</td><td>86531</td><td>0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>3</td><td>&quot;12of12inf&quot;</td></tr><tr><td>&quot;ZYMURGIES&quot;</td><td>86532</td><td>0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>3</td><td>&quot;12of12inf&quot;</td></tr><tr><td>&quot;ZYMURGY&quot;</td><td>86533</td><td>0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>3</td><td>&quot;12of12inf&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (86_531, 16)\n",
       "┌───────────┬─────────┬───────┬─────────────┬───┬─────────────┬────────────┬───────────┬───────────┐\n",
       "│ Word      ┆ Seq_num ┆ Word  ┆ Word        ┆ … ┆ Weak_Modal  ┆ Constraini ┆ Syllables ┆ Source    │\n",
       "│ ---       ┆ ---     ┆ Count ┆ Proportion  ┆   ┆ ---         ┆ ng         ┆ ---       ┆ ---       │\n",
       "│ str       ┆ i64     ┆ ---   ┆ ---         ┆   ┆ i64         ┆ ---        ┆ i64       ┆ str       │\n",
       "│           ┆         ┆ i64   ┆ f64         ┆   ┆             ┆ i64        ┆           ┆           │\n",
       "╞═══════════╪═════════╪═══════╪═════════════╪═══╪═════════════╪════════════╪═══════════╪═══════════╡\n",
       "│ AARDVARK  ┆ 1       ┆ 354   ┆ 1.5501e-8   ┆ … ┆ 0           ┆ 0          ┆ 2         ┆ 12of12inf │\n",
       "│ AARDVARKS ┆ 2       ┆ 3     ┆ 1.3136e-10  ┆ … ┆ 0           ┆ 0          ┆ 2         ┆ 12of12inf │\n",
       "│ ABACI     ┆ 3       ┆ 9     ┆ 3.9409e-10  ┆ … ┆ 0           ┆ 0          ┆ 3         ┆ 12of12inf │\n",
       "│ ABACK     ┆ 4       ┆ 29    ┆ 1.2698e-9   ┆ … ┆ 0           ┆ 0          ┆ 2         ┆ 12of12inf │\n",
       "│ ABACUS    ┆ 5       ┆ 8570  ┆ 3.7526e-7   ┆ … ┆ 0           ┆ 0          ┆ 3         ┆ 12of12inf │\n",
       "│ …         ┆ …       ┆ …     ┆ …           ┆ … ┆ …           ┆ …          ┆ …         ┆ …         │\n",
       "│ ZYGOTE    ┆ 86529   ┆ 50    ┆ 2.1894e-9   ┆ … ┆ 0           ┆ 0          ┆ 2         ┆ 12of12inf │\n",
       "│ ZYGOTES   ┆ 86530   ┆ 1     ┆ 4.3788e-11  ┆ … ┆ 0           ┆ 0          ┆ 2         ┆ 12of12inf │\n",
       "│ ZYGOTIC   ┆ 86531   ┆ 0     ┆ 0.0         ┆ … ┆ 0           ┆ 0          ┆ 3         ┆ 12of12inf │\n",
       "│ ZYMURGIES ┆ 86532   ┆ 0     ┆ 0.0         ┆ … ┆ 0           ┆ 0          ┆ 3         ┆ 12of12inf │\n",
       "│ ZYMURGY   ┆ 86533   ┆ 0     ┆ 0.0         ┆ … ┆ 0           ┆ 0          ┆ 3         ┆ 12of12inf │\n",
       "└───────────┴─────────┴───────┴─────────────┴───┴─────────────┴────────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_dict = pl.read_csv(r'C:\\Users\\310\\Desktop\\Progects_Py\\Parsim-sec\\src\\Analysis\\Loughran-McDonald_MasterDictionary_1993-2021.csv')\n",
    "lm_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple\n",
      "C:\\Users\\310\\Desktop\\Progects_Py\\cleared_files\\Apple%2520Inc.%2520(AAPL)%2520(CIK%25200000320193)_reports.parquet\n"
     ]
    }
   ],
   "source": [
    "df_dict = {}\n",
    "\n",
    "for company_name in COMPANY_NAME_LIST:\n",
    "\n",
    "    clean_name = company_name.split('%')[0]\n",
    "    print(clean_name)\n",
    "\n",
    "    df_name = f\"df_{clean_name}\"\n",
    "\n",
    "    file_path_partial = os.path.join(r\"C:\\Users\\310\\Desktop\\Progects_Py\\cleared_files\", company_name)\n",
    "    file_path = file_path_partial + '_reports.parquet'\n",
    "    print(file_path)\n",
    "\n",
    "    df = pl.read_parquet(file_path)\n",
    "\n",
    "    df_dict[df_name] = df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>2023-11-03</th></tr><tr><td>u32</td></tr></thead><tbody><tr><td>7985</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 1)\n",
       "┌────────────┐\n",
       "│ 2023-11-03 │\n",
       "│ ---        │\n",
       "│ u32        │\n",
       "╞════════════╡\n",
       "│ 7985       │\n",
       "└────────────┘"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dict[\"df_Apple\"].select(pl.col(\"2023-11-03\").is_null().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "total_num_of_rep = 0\n",
    "\n",
    "for value in df_dict.values():\n",
    "    total_num_of_rep += value.width\n",
    "print(total_num_of_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10371991\n"
     ]
    }
   ],
   "source": [
    "total_num_of_words = 0\n",
    "\n",
    "for value in df_dict.values():\n",
    "    for col in value:\n",
    "        total_num_of_words += col.count()\n",
    "\n",
    "print(total_num_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#average doc length\n",
    "average_word_count = total_num_of_words/total_num_of_rep\n",
    "ln_average_word_count = math.log(average_word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2692\n"
     ]
    }
   ],
   "source": [
    "#ENSURE CASE CoMpAtAbIlItY\n",
    "positive_words = lm_dict.filter(lm_dict[\"Positive\"] > 0).to_series().str.to_lowercase()\n",
    "\n",
    "negative_words = lm_dict.filter(lm_dict[\"Negative\"] > 0).to_series().str.to_lowercase()\n",
    "print(len(negative_words) + len(positive_words))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example series \n",
    "example_series = df_dict['df_3M'][df_dict['df_3M'].columns[1]]\n",
    "example_df = df_dict['df_3M']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the func, that appled to a series and get sentiment words from it. As an output we get a df with first col - grouped words that appeaps in LOUGHRAN dictionary and has >0 value in \"positive\" or \"negative\" cols. Secon col contain count of corresponding word in this document. Third col contain boolean, indicatin if this word has positive sentiment (True) or negative (False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (237, 3)\n",
      "┌────────────────┬──────────────┬──────────┐\n",
      "│ 2019-07-26     ┆ count in doc ┆ positive │\n",
      "│ ---            ┆ ---          ┆ ---      │\n",
      "│ str            ┆ u32          ┆ bool     │\n",
      "╞════════════════╪══════════════╪══════════╡\n",
      "│ barrier        ┆ 2            ┆ false    │\n",
      "│ investigations ┆ 2            ┆ false    │\n",
      "│ hazards        ┆ 2            ┆ false    │\n",
      "│ question       ┆ 2            ┆ false    │\n",
      "│ contend        ┆ 16           ┆ false    │\n",
      "│ …              ┆ …            ┆ …        │\n",
      "│ opportunities  ┆ 6            ┆ true     │\n",
      "│ enjoyment      ┆ 4            ┆ true     │\n",
      "│ better         ┆ 18           ┆ true     │\n",
      "│ improve        ┆ 22           ┆ true     │\n",
      "│ gain           ┆ 32           ┆ true     │\n",
      "└────────────────┴──────────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "def count_sentiment_w_in_doc(df_series):\n",
    "        \n",
    "        #grouped series that became a df, where each row is unique word and its count in document \n",
    "        num_of_w = df_series.value_counts().rename({\"count\": \"count in doc\"})\n",
    "       \n",
    "        \n",
    "        #first col of this df (only words by itself)\n",
    "        only_w = num_of_w[num_of_w.columns[0]]\n",
    "        \n",
    "\n",
    "        #Filterd df, there is only words that have positive or negative sentiment score in this document \n",
    "        pos_w = num_of_w.filter(only_w.is_in(positive_words)).with_columns(pl.lit(True).alias(\"positive\"))\n",
    "        neg_w = num_of_w.filter(only_w.is_in(negative_words)).with_columns(pl.lit(False).alias(\"positive\"))\n",
    "       \n",
    "        #Staked for one df for further operations \n",
    "        df_stacked = neg_w.vstack(pos_w)\n",
    "\n",
    "        return df_stacked\n",
    "    \n",
    "check = count_sentiment_w_in_doc(df_dict['df_3M'][df_dict['df_3M'].columns[1]])  \n",
    "print(check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the func that counts a number of docs with at least one occurense of the input word. It takes hole dictionary whith dataframes and particular word as an input. Then checks how many cols in each df contain this word, sum up all resulst and return a single value for each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_all_doc_occurence(check_str, df_dict):\n",
    "    count = 0\n",
    "    for df in df_dict.values():\n",
    "        count += df.select((pl.all() == check_str).sum() > 0).sum_horizontal()[0]\n",
    "        \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "289"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stringg = \"a\"\n",
    "in_all_doc_occurence(stringg, df_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the func that takes a df from count_sentiment_w_in_doc() and for each word in this df applies in_all_doc_occurence(), meaning that it counts all docs with at least one occurence of this word. The result of applying this func for each word in df is a series of integers showing counts for correcdonding word. This series augmented af col named \"count in all docs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_occurence_count(df_series, df_dict):\n",
    "   check = count_sentiment_w_in_doc(df_series).lazy()\n",
    "\n",
    "   counts = check.with_columns(pl.col(check.columns[0]).map_elements(lambda x: in_all_doc_occurence(x, df_dict)).alias(\"count in all docs\")).collect()\n",
    "   return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (237, 4)\n",
      "┌──────────────┬──────────────┬──────────┬───────────────────┐\n",
      "│ 2019-07-26   ┆ count in doc ┆ positive ┆ count in all docs │\n",
      "│ ---          ┆ ---          ┆ ---      ┆ ---               │\n",
      "│ str          ┆ u32          ┆ bool     ┆ i64               │\n",
      "╞══════════════╪══════════════╪══════════╪═══════════════════╡\n",
      "│ forfeited    ┆ 2            ┆ false    ┆ 53                │\n",
      "│ defendants   ┆ 74           ┆ false    ┆ 137               │\n",
      "│ fraudulent   ┆ 8            ┆ false    ┆ 77                │\n",
      "│ recessionary ┆ 2            ┆ false    ┆ 17                │\n",
      "│ interruption ┆ 2            ┆ false    ┆ 103               │\n",
      "│ …            ┆ …            ┆ …        ┆ …                 │\n",
      "│ adequately   ┆ 2            ┆ true     ┆ 69                │\n",
      "│ successfully ┆ 2            ┆ true     ┆ 155               │\n",
      "│ gains        ┆ 58           ┆ true     ┆ 258               │\n",
      "│ enhancing    ┆ 4            ┆ true     ┆ 76                │\n",
      "│ successful   ┆ 2            ┆ true     ┆ 141               │\n",
      "└──────────────┴──────────────┴──────────┴───────────────────┘\n"
     ]
    }
   ],
   "source": [
    "res_df = total_occurence_count(example_series, df_dict)\n",
    "print(res_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the func that takes as an argument resulting df, wich was obtained from total_occurence_count(). Recal that this df contains information about one document (one col in df). This func calculate weighted and raw scores using precomputed metrics. Returns a list with weighted score and raw score. Weights are calculated based on this formula: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "w_{i,j} = \n",
    "\\begin{cases} \n",
    "\\left(\\frac{1 + \\log(tf_{i,j})}{1 + \\log(a)}\\right) \\log\\left(\\frac{N}{df_i}\\right) & \\text{if } tf_{i,j} \\geq 1 \\\\\n",
    "0 & \\text{otherwise} \n",
    "\\end{cases}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N represents the total number of 10-Ks in the sample, dfi the number of documents containing at least one occurrence of the i th word, tfi,j the raw count of the i th word in the j th document, and a the average word count in the document.\n",
    "\n",
    "The formula is from:\n",
    "\n",
    "Loughran T., McDonald B. When is a liability not a liability? Textual analysis, dictionaries, and 10‐Ks //The Journal of finance. – 2011. – Т. 66. – №. 1. – С. 35-65."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_score(res_df):\n",
    "\n",
    "    res_df.lazy()\n",
    "\n",
    "    res = res_df.with_columns((((1 + pl.col(res_df.columns[1]).log())/(1 + ln_average_word_count))*((total_num_of_rep/pl.col(res_df.columns[3])).log())).alias(\"metrics\"))\n",
    "\n",
    "    w_pos_sen = res.filter(pl.col('positive') == True).select(pl.col(res.columns[4])).sum().item()\n",
    "    w_neg_sen = res.filter(pl.col('positive') == False).select(pl.col(res.columns[4])).sum().item()\n",
    "\n",
    "    w_score = w_pos_sen - w_neg_sen\n",
    "    score = res.select(pl.col('positive')).sum().item()*2 - len(res)\n",
    "\n",
    "    scores = [w_score, score]\n",
    "    \n",
    "    return scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General loop that iterates over dfs and over it columns. It uses predefined finctions to calculate scores and save it as parquet files. Each parquet file named with company name is a dataframe with col names as field dates, first row is weighted scores and second row is raw scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration for Apple%2520Inc.%2520(AAPL)%2520(CIK%25200000320193) is done successfully\n",
      "Attempting to write to: full_10_Q_scores\\Apple%2520Inc.%2520(AAPL)%2520(CIK%25200000320193)_f_10_Q_score_df.parquet\n",
      "full_10_Q_scores\\Apple%2520Inc.%2520(AAPL)%2520(CIK%25200000320193)_f_10_Q_score_df.parquet created successfully\n",
      "Iteration for MICROSOFT%2520CORP%2520(MSFT)%2520(CIK%25200000789019) is done successfully\n",
      "Attempting to write to: full_10_Q_scores\\MICROSOFT%2520CORP%2520(MSFT)%2520(CIK%25200000789019)_f_10_Q_score_df.parquet\n",
      "full_10_Q_scores\\MICROSOFT%2520CORP%2520(MSFT)%2520(CIK%25200000789019)_f_10_Q_score_df.parquet created successfully\n",
      "Iteration for BigCommerce%2520Holdings%252C%2520Inc.%2520(BIGC)%2520(CIK%25200001626450) is done successfully\n",
      "Attempting to write to: full_10_Q_scores\\BigCommerce%2520Holdings%252C%2520Inc.%2520(BIGC)%2520(CIK%25200001626450)_f_10_Q_score_df.parquet\n",
      "full_10_Q_scores\\BigCommerce%2520Holdings%252C%2520Inc.%2520(BIGC)%2520(CIK%25200001626450)_f_10_Q_score_df.parquet created successfully\n",
      "Iteration for ROKU%252C%2520INC%2520(ROKU)%2520(CIK%25200001428439) is done successfully\n",
      "Attempting to write to: full_10_Q_scores\\ROKU%252C%2520INC%2520(ROKU)%2520(CIK%25200001428439)_f_10_Q_score_df.parquet\n",
      "full_10_Q_scores\\ROKU%252C%2520INC%2520(ROKU)%2520(CIK%25200001428439)_f_10_Q_score_df.parquet created successfully\n",
      "Iteration for JPMORGAN%2520CHASE%2520(CIK%25200000019617) is done successfully\n",
      "Attempting to write to: full_10_Q_scores\\JPMORGAN%2520CHASE%2520(CIK%25200000019617)_f_10_Q_score_df.parquet\n",
      "full_10_Q_scores\\JPMORGAN%2520CHASE%2520(CIK%25200000019617)_f_10_Q_score_df.parquet created successfully\n",
      "Iteration for VISA%2520INC.%2520(V)%2520(CIK%25200001403161) is done successfully\n",
      "Attempting to write to: full_10_Q_scores\\VISA%2520INC.%2520(V)%2520(CIK%25200001403161)_f_10_Q_score_df.parquet\n",
      "full_10_Q_scores\\VISA%2520INC.%2520(V)%2520(CIK%25200001403161)_f_10_Q_score_df.parquet created successfully\n",
      "Iteration for Block%252C%2520Inc.%2520(SQ%252C%2520BSQKZ)%2520(CIK%25200001512673) is done successfully\n",
      "Attempting to write to: full_10_Q_scores\\Block%252C%2520Inc.%2520(SQ%252C%2520BSQKZ)%2520(CIK%25200001512673)_f_10_Q_score_df.parquet\n",
      "full_10_Q_scores\\Block%252C%2520Inc.%2520(SQ%252C%2520BSQKZ)%2520(CIK%25200001512673)_f_10_Q_score_df.parquet created successfully\n",
      "Iteration for Robinhood%2520Markets%252C%2520Inc.%2520(HOOD)%2520(CIK%25200001783879) is done successfully\n",
      "Attempting to write to: full_10_Q_scores\\Robinhood%2520Markets%252C%2520Inc.%2520(HOOD)%2520(CIK%25200001783879)_f_10_Q_score_df.parquet\n",
      "full_10_Q_scores\\Robinhood%2520Markets%252C%2520Inc.%2520(HOOD)%2520(CIK%25200001783879)_f_10_Q_score_df.parquet created successfully\n",
      "Iteration for JOHNSON%252C%252C%2520JOHNSON%2520(JNJ)%2520(CIK%25200000200406) is done successfully\n",
      "Attempting to write to: full_10_Q_scores\\JOHNSON%252C%252C%2520JOHNSON%2520(JNJ)%2520(CIK%25200000200406)_f_10_Q_score_df.parquet\n",
      "full_10_Q_scores\\JOHNSON%252C%252C%2520JOHNSON%2520(JNJ)%2520(CIK%25200000200406)_f_10_Q_score_df.parquet created successfully\n",
      "Iteration for PFIZER%2520INC%2520(PFE)%2520(CIK%25200000078003) is done successfully\n",
      "Attempting to write to: full_10_Q_scores\\PFIZER%2520INC%2520(PFE)%2520(CIK%25200000078003)_f_10_Q_score_df.parquet\n",
      "full_10_Q_scores\\PFIZER%2520INC%2520(PFE)%2520(CIK%25200000078003)_f_10_Q_score_df.parquet created successfully\n",
      "Iteration for Moderna%252C%2520Inc.%2520(MRNA)%2520(CIK%25200001682852) is done successfully\n",
      "Attempting to write to: full_10_Q_scores\\Moderna%252C%2520Inc.%2520(MRNA)%2520(CIK%25200001682852)_f_10_Q_score_df.parquet\n",
      "full_10_Q_scores\\Moderna%252C%2520Inc.%2520(MRNA)%2520(CIK%25200001682852)_f_10_Q_score_df.parquet created successfully\n",
      "Iteration for Teladoc%2520Health%252C%2520Inc.%2520(TDOC)%2520(CIK%25200001477449) is done successfully\n",
      "Attempting to write to: full_10_Q_scores\\Teladoc%2520Health%252C%2520Inc.%2520(TDOC)%2520(CIK%25200001477449)_f_10_Q_score_df.parquet\n",
      "full_10_Q_scores\\Teladoc%2520Health%252C%2520Inc.%2520(TDOC)%2520(CIK%25200001477449)_f_10_Q_score_df.parquet created successfully\n",
      "Iteration for EXXON%2520MOBIL%2520CORP%2520(XOM)%2520(CIK%25200000034088) is done successfully\n",
      "Attempting to write to: full_10_Q_scores\\EXXON%2520MOBIL%2520CORP%2520(XOM)%2520(CIK%25200000034088)_f_10_Q_score_df.parquet\n",
      "full_10_Q_scores\\EXXON%2520MOBIL%2520CORP%2520(XOM)%2520(CIK%25200000034088)_f_10_Q_score_df.parquet created successfully\n",
      "Iteration for CHEVRON%2520CORP%2520(CVX)%2520(CIK%25200000093410) is done successfully\n",
      "Attempting to write to: full_10_Q_scores\\CHEVRON%2520CORP%2520(CVX)%2520(CIK%25200000093410)_f_10_Q_score_df.parquet\n",
      "full_10_Q_scores\\CHEVRON%2520CORP%2520(CVX)%2520(CIK%25200000093410)_f_10_Q_score_df.parquet created successfully\n",
      "Iteration for FIRST%2520SOLAR%252C%2520INC.%2520(FSLR)%2520(CIK%25200001274494) is done successfully\n",
      "Attempting to write to: full_10_Q_scores\\FIRST%2520SOLAR%252C%2520INC.%2520(FSLR)%2520(CIK%25200001274494)_f_10_Q_score_df.parquet\n",
      "full_10_Q_scores\\FIRST%2520SOLAR%252C%2520INC.%2520(FSLR)%2520(CIK%25200001274494)_f_10_Q_score_df.parquet created successfully\n",
      "Iteration for PLUG%2520POWER%2520INC%2520(PLUG)%2520(CIK%25200001093691) is done successfully\n",
      "Attempting to write to: full_10_Q_scores\\PLUG%2520POWER%2520INC%2520(PLUG)%2520(CIK%25200001093691)_f_10_Q_score_df.parquet\n",
      "full_10_Q_scores\\PLUG%2520POWER%2520INC%2520(PLUG)%2520(CIK%25200001093691)_f_10_Q_score_df.parquet created successfully\n",
      "Iteration for GENERAL%252CELECTRIC%2520CO%2520(GE)%2520(CIK%25200000040545) is done successfully\n",
      "Attempting to write to: full_10_Q_scores\\GENERAL%252CELECTRIC%2520CO%2520(GE)%2520(CIK%25200000040545)_f_10_Q_score_df.parquet\n",
      "full_10_Q_scores\\GENERAL%252CELECTRIC%2520CO%2520(GE)%2520(CIK%25200000040545)_f_10_Q_score_df.parquet created successfully\n",
      "Iteration for 3M%2520CO%2520(MMM)%2520(CIK%25200000066740) is done successfully\n",
      "Attempting to write to: full_10_Q_scores\\3M%2520CO%2520(MMM)%2520(CIK%25200000066740)_f_10_Q_score_df.parquet\n",
      "full_10_Q_scores\\3M%2520CO%2520(MMM)%2520(CIK%25200000066740)_f_10_Q_score_df.parquet created successfully\n",
      "Iteration for CATERPILLAR%2520INC%2520(CAT)%2520(CIK%25200000018230) is done successfully\n",
      "Attempting to write to: full_10_Q_scores\\CATERPILLAR%2520INC%2520(CAT)%2520(CIK%25200000018230)_f_10_Q_score_df.parquet\n",
      "full_10_Q_scores\\CATERPILLAR%2520INC%2520(CAT)%2520(CIK%25200000018230)_f_10_Q_score_df.parquet created successfully\n",
      "Iteration for FASTENAL%2520CO%2520(FAST)%2520(CIK%25200000815556) is done successfully\n",
      "Attempting to write to: full_10_Q_scores\\FASTENAL%2520CO%2520(FAST)%2520(CIK%25200000815556)_f_10_Q_score_df.parquet\n",
      "full_10_Q_scores\\FASTENAL%2520CO%2520(FAST)%2520(CIK%25200000815556)_f_10_Q_score_df.parquet created successfully\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for df in df_dict.values():\n",
    "\n",
    "    score_dict = {}\n",
    "\n",
    "    for col in df:\n",
    "        \n",
    "        res_df = total_occurence_count(col, df_dict)\n",
    "        scores = compute_score(res_df)\n",
    "\n",
    "        score_dict[col.name] =  scores\n",
    "    \n",
    "    df = pl.DataFrame(score_dict)\n",
    "    \n",
    "    print(f'Iteration for {col[0]} is done successfully')\n",
    "\n",
    " # Determine the output directory and file name\n",
    "    output_dir = os.path.join('.', 'full_10_Q_scores')\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    file_name_new = f\"{col[0]}_f_10_Q_score_df.parquet\"\n",
    "    full_path = os.path.join(output_dir, file_name_new)\n",
    "    full_path = os.path.normpath(full_path)\n",
    "\n",
    "    print(f\"Attempting to write to: {full_path}\")\n",
    "\n",
    "    # Write the DataFrame to Parquet\n",
    "    df.write_parquet(full_path)\n",
    "\n",
    "    print(f\"{full_path} created successfully\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "jupyter nbconvert --to html Parsim-sec\\src\\Analysis\\Full_10_Q_scores_calculating.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
