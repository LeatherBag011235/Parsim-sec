{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pysentiment2 as ps\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "import urllib.parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPANY_NAME_LIST = ['Apple%2520Inc.%2520(AAPL)%2520(CIK%25200000320193)', 'MICROSOFT%2520CORP%2520(MSFT)%2520(CIK%25200000789019)', \n",
    "                     'BigCommerce%2520Holdings%252C%2520Inc.%2520(BIGC)%2520(CIK%25200001626450)', 'ROKU%252C%2520INC%2520(ROKU)%2520(CIK%25200001428439)', \n",
    "                     'JPMORGAN%2520CHASE%2520%2526%2520CO%2520(JPM%252C%2520AMJ%252C%2520AMJB%252C%2520JPM)%2520(CIK%25200000019617)', 'VISA%2520INC.%2520(V)%2520(CIK%25200001403161)', \n",
    "                     'Block%252C%2520Inc.%2520(SQ%252C%2520BSQKZ)%2520(CIK%25200001512673)', 'Robinhood%2520Markets%252C%2520Inc.%2520(HOOD)%2520(CIK%25200001783879)', \n",
    "                     'JOHNSON%252C%252C%2520JOHNSON%2520(JNJ)%2520(CIK%25200000200406)', 'PFIZER%2520INC%2520(PFE)%2520(CIK%25200000078003)', \n",
    "                     'Moderna%252C%2520Inc.%2520(MRNA)%2520(CIK%25200001682852)', 'Teladoc%2520Health%252C%2520Inc.%2520(TDOC)%2520(CIK%25200001477449)', \n",
    "                     'EXXON%2520MOBIL%2520CORP%2520(XOM)%2520(CIK%25200000034088)', 'CHEVRON%2520CORP%2520(CVX)%2520(CIK%25200000093410)', \n",
    "                     'FIRST%2520SOLAR%252C%2520INC.%2520(FSLR)%2520(CIK%25200001274494)', 'PLUG%2520POWER%2520INC%2520(PLUG)%2520(CIK%25200001093691)', \n",
    "                     'GENERAL%252CELECTRIC%2520CO%2520(GE)%2520(CIK%25200000040545)', '3M%2520CO%2520(MMM)%2520(CIK%25200000066740)', \n",
    "                     'CATERPILLAR%2520INC%2520(CAT)%2520(CIK%25200000018230)', 'FASTENAL%2520CO%2520(FAST)%2520(CIK%25200000815556)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (86_531, 16)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Word</th><th>Seq_num</th><th>Word Count</th><th>Word Proportion</th><th>Average Proportion</th><th>Std Dev</th><th>Doc Count</th><th>Negative</th><th>Positive</th><th>Uncertainty</th><th>Litigious</th><th>Strong_Modal</th><th>Weak_Modal</th><th>Constraining</th><th>Syllables</th><th>Source</th></tr><tr><td>str</td><td>i64</td><td>i64</td><td>f64</td><td>f64</td><td>f64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>str</td></tr></thead><tbody><tr><td>&quot;AARDVARK&quot;</td><td>1</td><td>354</td><td>1.5501e-8</td><td>1.4226e-8</td><td>0.000004</td><td>99</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>2</td><td>&quot;12of12inf&quot;</td></tr><tr><td>&quot;AARDVARKS&quot;</td><td>2</td><td>3</td><td>1.3136e-10</td><td>8.6538e-12</td><td>9.2417e-9</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>2</td><td>&quot;12of12inf&quot;</td></tr><tr><td>&quot;ABACI&quot;</td><td>3</td><td>9</td><td>3.9409e-10</td><td>1.1697e-10</td><td>5.2905e-8</td><td>7</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>3</td><td>&quot;12of12inf&quot;</td></tr><tr><td>&quot;ABACK&quot;</td><td>4</td><td>29</td><td>1.2698e-9</td><td>6.6547e-10</td><td>1.5951e-7</td><td>28</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>2</td><td>&quot;12of12inf&quot;</td></tr><tr><td>&quot;ABACUS&quot;</td><td>5</td><td>8570</td><td>3.7526e-7</td><td>3.8095e-7</td><td>0.000035</td><td>1108</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>3</td><td>&quot;12of12inf&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;ZYGOTE&quot;</td><td>86529</td><td>50</td><td>2.1894e-9</td><td>8.7293e-10</td><td>1.8860e-7</td><td>35</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>2</td><td>&quot;12of12inf&quot;</td></tr><tr><td>&quot;ZYGOTES&quot;</td><td>86530</td><td>1</td><td>4.3788e-11</td><td>1.8095e-11</td><td>1.9324e-8</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>2</td><td>&quot;12of12inf&quot;</td></tr><tr><td>&quot;ZYGOTIC&quot;</td><td>86531</td><td>0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>3</td><td>&quot;12of12inf&quot;</td></tr><tr><td>&quot;ZYMURGIES&quot;</td><td>86532</td><td>0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>3</td><td>&quot;12of12inf&quot;</td></tr><tr><td>&quot;ZYMURGY&quot;</td><td>86533</td><td>0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>3</td><td>&quot;12of12inf&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (86_531, 16)\n",
       "┌───────────┬─────────┬───────┬─────────────┬───┬─────────────┬────────────┬───────────┬───────────┐\n",
       "│ Word      ┆ Seq_num ┆ Word  ┆ Word        ┆ … ┆ Weak_Modal  ┆ Constraini ┆ Syllables ┆ Source    │\n",
       "│ ---       ┆ ---     ┆ Count ┆ Proportion  ┆   ┆ ---         ┆ ng         ┆ ---       ┆ ---       │\n",
       "│ str       ┆ i64     ┆ ---   ┆ ---         ┆   ┆ i64         ┆ ---        ┆ i64       ┆ str       │\n",
       "│           ┆         ┆ i64   ┆ f64         ┆   ┆             ┆ i64        ┆           ┆           │\n",
       "╞═══════════╪═════════╪═══════╪═════════════╪═══╪═════════════╪════════════╪═══════════╪═══════════╡\n",
       "│ AARDVARK  ┆ 1       ┆ 354   ┆ 1.5501e-8   ┆ … ┆ 0           ┆ 0          ┆ 2         ┆ 12of12inf │\n",
       "│ AARDVARKS ┆ 2       ┆ 3     ┆ 1.3136e-10  ┆ … ┆ 0           ┆ 0          ┆ 2         ┆ 12of12inf │\n",
       "│ ABACI     ┆ 3       ┆ 9     ┆ 3.9409e-10  ┆ … ┆ 0           ┆ 0          ┆ 3         ┆ 12of12inf │\n",
       "│ ABACK     ┆ 4       ┆ 29    ┆ 1.2698e-9   ┆ … ┆ 0           ┆ 0          ┆ 2         ┆ 12of12inf │\n",
       "│ ABACUS    ┆ 5       ┆ 8570  ┆ 3.7526e-7   ┆ … ┆ 0           ┆ 0          ┆ 3         ┆ 12of12inf │\n",
       "│ …         ┆ …       ┆ …     ┆ …           ┆ … ┆ …           ┆ …          ┆ …         ┆ …         │\n",
       "│ ZYGOTE    ┆ 86529   ┆ 50    ┆ 2.1894e-9   ┆ … ┆ 0           ┆ 0          ┆ 2         ┆ 12of12inf │\n",
       "│ ZYGOTES   ┆ 86530   ┆ 1     ┆ 4.3788e-11  ┆ … ┆ 0           ┆ 0          ┆ 2         ┆ 12of12inf │\n",
       "│ ZYGOTIC   ┆ 86531   ┆ 0     ┆ 0.0         ┆ … ┆ 0           ┆ 0          ┆ 3         ┆ 12of12inf │\n",
       "│ ZYMURGIES ┆ 86532   ┆ 0     ┆ 0.0         ┆ … ┆ 0           ┆ 0          ┆ 3         ┆ 12of12inf │\n",
       "│ ZYMURGY   ┆ 86533   ┆ 0     ┆ 0.0         ┆ … ┆ 0           ┆ 0          ┆ 3         ┆ 12of12inf │\n",
       "└───────────┴─────────┴───────┴─────────────┴───┴─────────────┴────────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_dict = pl.read_csv(r'C:\\Users\\310\\Desktop\\Progects_Py\\Parsim-sec\\src\\Analysis\\Loughran-McDonald_MasterDictionary_1993-2021.csv')\n",
    "lm_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL\n",
      "C:\\Users\\310\\Desktop\\Progects_Py\\prepared_data\\full_10Q_10K_without_tabels\\Apple%2520Inc.%2520(AAPL)%2520(CIK%25200000320193)_reports.parquet\n",
      "MSFT\n",
      "C:\\Users\\310\\Desktop\\Progects_Py\\prepared_data\\full_10Q_10K_without_tabels\\MICROSOFT%2520CORP%2520(MSFT)%2520(CIK%25200000789019)_reports.parquet\n",
      "BIGC\n",
      "C:\\Users\\310\\Desktop\\Progects_Py\\prepared_data\\full_10Q_10K_without_tabels\\BigCommerce%2520Holdings%252C%2520Inc.%2520(BIGC)%2520(CIK%25200001626450)_reports.parquet\n",
      "ROKU\n",
      "C:\\Users\\310\\Desktop\\Progects_Py\\prepared_data\\full_10Q_10K_without_tabels\\ROKU%252C%2520INC%2520(ROKU)%2520(CIK%25200001428439)_reports.parquet\n",
      "JPM\n",
      "C:\\Users\\310\\Desktop\\Progects_Py\\prepared_data\\full_10Q_10K_without_tabels\\JPMORGAN%2520CHASE%2520%2526%2520CO%2520(JPM%252C%2520AMJ%252C%2520AMJB%252C%2520JPM)%2520(CIK%25200000019617)_reports.parquet\n",
      "V\n",
      "C:\\Users\\310\\Desktop\\Progects_Py\\prepared_data\\full_10Q_10K_without_tabels\\VISA%2520INC.%2520(V)%2520(CIK%25200001403161)_reports.parquet\n",
      "SQ\n",
      "C:\\Users\\310\\Desktop\\Progects_Py\\prepared_data\\full_10Q_10K_without_tabels\\Block%252C%2520Inc.%2520(SQ%252C%2520BSQKZ)%2520(CIK%25200001512673)_reports.parquet\n",
      "HOOD\n",
      "C:\\Users\\310\\Desktop\\Progects_Py\\prepared_data\\full_10Q_10K_without_tabels\\Robinhood%2520Markets%252C%2520Inc.%2520(HOOD)%2520(CIK%25200001783879)_reports.parquet\n",
      "JNJ\n",
      "C:\\Users\\310\\Desktop\\Progects_Py\\prepared_data\\full_10Q_10K_without_tabels\\JOHNSON%252C%252C%2520JOHNSON%2520(JNJ)%2520(CIK%25200000200406)_reports.parquet\n",
      "PFE\n",
      "C:\\Users\\310\\Desktop\\Progects_Py\\prepared_data\\full_10Q_10K_without_tabels\\PFIZER%2520INC%2520(PFE)%2520(CIK%25200000078003)_reports.parquet\n",
      "MRNA\n",
      "C:\\Users\\310\\Desktop\\Progects_Py\\prepared_data\\full_10Q_10K_without_tabels\\Moderna%252C%2520Inc.%2520(MRNA)%2520(CIK%25200001682852)_reports.parquet\n",
      "TDOC\n",
      "C:\\Users\\310\\Desktop\\Progects_Py\\prepared_data\\full_10Q_10K_without_tabels\\Teladoc%2520Health%252C%2520Inc.%2520(TDOC)%2520(CIK%25200001477449)_reports.parquet\n",
      "XOM\n",
      "C:\\Users\\310\\Desktop\\Progects_Py\\prepared_data\\full_10Q_10K_without_tabels\\EXXON%2520MOBIL%2520CORP%2520(XOM)%2520(CIK%25200000034088)_reports.parquet\n",
      "CVX\n",
      "C:\\Users\\310\\Desktop\\Progects_Py\\prepared_data\\full_10Q_10K_without_tabels\\CHEVRON%2520CORP%2520(CVX)%2520(CIK%25200000093410)_reports.parquet\n",
      "FSLR\n",
      "C:\\Users\\310\\Desktop\\Progects_Py\\prepared_data\\full_10Q_10K_without_tabels\\FIRST%2520SOLAR%252C%2520INC.%2520(FSLR)%2520(CIK%25200001274494)_reports.parquet\n",
      "PLUG\n",
      "C:\\Users\\310\\Desktop\\Progects_Py\\prepared_data\\full_10Q_10K_without_tabels\\PLUG%2520POWER%2520INC%2520(PLUG)%2520(CIK%25200001093691)_reports.parquet\n",
      "GE\n",
      "C:\\Users\\310\\Desktop\\Progects_Py\\prepared_data\\full_10Q_10K_without_tabels\\GENERAL%252CELECTRIC%2520CO%2520(GE)%2520(CIK%25200000040545)_reports.parquet\n",
      "MMM\n",
      "C:\\Users\\310\\Desktop\\Progects_Py\\prepared_data\\full_10Q_10K_without_tabels\\3M%2520CO%2520(MMM)%2520(CIK%25200000066740)_reports.parquet\n",
      "CAT\n",
      "C:\\Users\\310\\Desktop\\Progects_Py\\prepared_data\\full_10Q_10K_without_tabels\\CATERPILLAR%2520INC%2520(CAT)%2520(CIK%25200000018230)_reports.parquet\n",
      "FAST\n",
      "C:\\Users\\310\\Desktop\\Progects_Py\\prepared_data\\full_10Q_10K_without_tabels\\FASTENAL%2520CO%2520(FAST)%2520(CIK%25200000815556)_reports.parquet\n"
     ]
    }
   ],
   "source": [
    "#old version for dfs without 10-K reports, full text (downloaded, from div)\n",
    "df_dict = {}\n",
    "\n",
    "for company_name in COMPANY_NAME_LIST:\n",
    "\n",
    "    company_name_dec = urllib.parse.unquote_plus(company_name)\n",
    "\n",
    "    match = re.search(r'\\((.*?)\\)', company_name_dec)\n",
    "\n",
    "    if not match:\n",
    "        print(f\"Ticker symbol for {company_name} is not found\")\n",
    "\n",
    "    reg_output = match.group(1).split('%')\n",
    "    ticker_symbol = reg_output[0]\n",
    "\n",
    "    print(ticker_symbol)\n",
    "\n",
    "    df_name = f\"{ticker_symbol}\"\n",
    "\n",
    "    file_path_partial = os.path.join(r\"C:\\Users\\310\\Desktop\\Progects_Py\\prepared_data\\full_10Q_10K_without_tabels\", company_name)\n",
    "    file_path = file_path_partial + '_reports.parquet'\n",
    "    print(file_path)\n",
    "\n",
    "    df = pl.read_parquet(file_path)\n",
    "\n",
    "    df_dict[df_name] = df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "392\n"
     ]
    }
   ],
   "source": [
    "total_num_of_rep = 0\n",
    "\n",
    "for value in df_dict.values():\n",
    "    total_num_of_rep += value.width\n",
    "print(total_num_of_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13102343\n"
     ]
    }
   ],
   "source": [
    "total_num_of_words = 0\n",
    "\n",
    "for value in df_dict.values():\n",
    "    for col in value:\n",
    "        total_num_of_words += col.count()\n",
    "\n",
    "print(total_num_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average doc length in words: 33424\n"
     ]
    }
   ],
   "source": [
    "#average doc length\n",
    "average_word_count = total_num_of_words/total_num_of_rep\n",
    "print(f'Average doc length in words: {round(average_word_count)}')\n",
    "ln_average_word_count = math.log(average_word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2692\n"
     ]
    }
   ],
   "source": [
    "#ENSURE CASE CoMpAtAbIlItY\n",
    "positive_words = lm_dict.filter(lm_dict[\"Positive\"] > 0).to_series().str.to_lowercase()\n",
    "\n",
    "negative_words = lm_dict.filter(lm_dict[\"Negative\"] > 0).to_series().str.to_lowercase()\n",
    "print(len(negative_words) + len(positive_words))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (35_789, 20)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>2019-07-16</th><th>2019-10-16</th><th>2020-02-06</th><th>2020-04-17</th><th>2020-07-17</th><th>2020-10-16</th><th>2021-02-08</th><th>2021-04-16</th><th>2021-07-16</th><th>2021-10-15</th><th>2022-02-07</th><th>2022-04-18</th><th>2022-07-18</th><th>2022-10-18</th><th>2023-02-07</th><th>2023-04-18</th><th>2023-07-18</th><th>2023-10-17</th><th>2024-02-06</th><th>2024-04-16</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;Document&quot;</td><td>&quot;Document&quot;</td><td>&quot;Document&quot;</td><td>&quot;Document&quot;</td><td>&quot;Document&quot;</td><td>&quot;of&quot;</td><td>&quot;of&quot;</td><td>&quot;of&quot;</td><td>&quot;of&quot;</td><td>&quot;of&quot;</td><td>&quot;of&quot;</td><td>&quot;of&quot;</td><td>&quot;of&quot;</td><td>&quot;of&quot;</td><td>&quot;of&quot;</td><td>&quot;of&quot;</td><td>&quot;of&quot;</td><td>&quot;of&quot;</td><td>&quot;of&quot;</td><td>&quot;of&quot;</td></tr><tr><td>&quot;usgaapAddition…</td><td>&quot;usgaapAddition…</td><td>&quot;usgaapAddition…</td><td>&quot;usgaapAccumula…</td><td>&quot;usgaapRetained…</td><td>&quot;ContentsUNITED…</td><td>&quot;ContentsUNITED…</td><td>&quot;ContentsUNITED…</td><td>&quot;ContentsUNITED…</td><td>&quot;ContentsUNITED…</td><td>&quot;ContentsUNITED…</td><td>&quot;ContentsUNITED…</td><td>&quot;ContentsUNITED…</td><td>&quot;ContentsUNITED…</td><td>&quot;ContentsUNITED…</td><td>&quot;ContentsUNITED…</td><td>&quot;ContentsUNITED…</td><td>&quot;ContentsUNITED…</td><td>&quot;ContentsUNITED…</td><td>&quot;ContentsUNITED…</td></tr><tr><td>&quot;usgaapAccumula…</td><td>&quot;usgaapAccumula…</td><td>&quot;usgaapAccumula…</td><td>&quot;usgaapAccumula…</td><td>&quot;usgaapAccumula…</td><td>&quot;STATESSECURITI…</td><td>&quot;STATESSECURITI…</td><td>&quot;STATESSECURITI…</td><td>&quot;STATESSECURITI…</td><td>&quot;STATESSECURITI…</td><td>&quot;STATESSECURITI…</td><td>&quot;STATESSECURITI…</td><td>&quot;STATESSECURITI…</td><td>&quot;STATESSECURITI…</td><td>&quot;STATESSECURITI…</td><td>&quot;STATESSECURITI…</td><td>&quot;STATESSECURITI…</td><td>&quot;STATESSECURITI…</td><td>&quot;STATESSECURITI…</td><td>&quot;STATESSECURITI…</td></tr><tr><td>&quot;usgaapAccumula…</td><td>&quot;usgaapRetained…</td><td>&quot;usgaapRetained…</td><td>&quot;usgaapAccumula…</td><td>&quot;usgaapAddition…</td><td>&quot;AND&quot;</td><td>&quot;AND&quot;</td><td>&quot;AND&quot;</td><td>&quot;AND&quot;</td><td>&quot;AND&quot;</td><td>&quot;AND&quot;</td><td>&quot;AND&quot;</td><td>&quot;AND&quot;</td><td>&quot;AND&quot;</td><td>&quot;AND&quot;</td><td>&quot;AND&quot;</td><td>&quot;AND&quot;</td><td>&quot;AND&quot;</td><td>&quot;AND&quot;</td><td>&quot;AND&quot;</td></tr><tr><td>&quot;usgaapAccumula…</td><td>&quot;usgaapRetained…</td><td>&quot;usgaapAccumula…</td><td>&quot;usgaapCommonSt…</td><td>&quot;usgaapCommonSt…</td><td>&quot;EXCHANGE&quot;</td><td>&quot;EXCHANGE&quot;</td><td>&quot;EXCHANGE&quot;</td><td>&quot;EXCHANGE&quot;</td><td>&quot;EXCHANGE&quot;</td><td>&quot;EXCHANGE&quot;</td><td>&quot;EXCHANGE&quot;</td><td>&quot;EXCHANGE&quot;</td><td>&quot;EXCHANGE&quot;</td><td>&quot;EXCHANGE&quot;</td><td>&quot;EXCHANGE&quot;</td><td>&quot;EXCHANGE&quot;</td><td>&quot;EXCHANGE&quot;</td><td>&quot;EXCHANGE&quot;</td><td>&quot;EXCHANGE&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;capacities&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;and&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;on&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;the&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;date&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (35_789, 20)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ 2019-07-1 ┆ 2019-10-1 ┆ 2020-02-0 ┆ 2020-04-1 ┆ … ┆ 2023-07-1 ┆ 2023-10-1 ┆ 2024-02-0 ┆ 2024-04- │\n",
       "│ 6         ┆ 6         ┆ 6         ┆ 7         ┆   ┆ 8         ┆ 7         ┆ 6         ┆ 16       │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│ str       ┆ str       ┆ str       ┆ str       ┆   ┆ str       ┆ str       ┆ str       ┆ str      │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ Document  ┆ Document  ┆ Document  ┆ Document  ┆ … ┆ of        ┆ of        ┆ of        ┆ of       │\n",
       "│ usgaapAdd ┆ usgaapAdd ┆ usgaapAdd ┆ usgaapAcc ┆ … ┆ ContentsU ┆ ContentsU ┆ ContentsU ┆ Contents │\n",
       "│ itionalPa ┆ itionalPa ┆ itionalPa ┆ umulatedO ┆   ┆ NITED     ┆ NITED     ┆ NITED     ┆ UNITED   │\n",
       "│ idInCapit ┆ idInCapit ┆ idInCapit ┆ therCompr ┆   ┆           ┆           ┆           ┆          │\n",
       "│ alMem…    ┆ alMem…    ┆ alMem…    ┆ ehens…    ┆   ┆           ┆           ┆           ┆          │\n",
       "│ usgaapAcc ┆ usgaapAcc ┆ usgaapAcc ┆ usgaapAcc ┆ … ┆ STATESSEC ┆ STATESSEC ┆ STATESSEC ┆ STATESSE │\n",
       "│ umulatedO ┆ umulatedO ┆ umulatedO ┆ umulatedO ┆   ┆ URITIES   ┆ URITIES   ┆ URITIES   ┆ CURITIES │\n",
       "│ therCompr ┆ therCompr ┆ therCompr ┆ therCompr ┆   ┆           ┆           ┆           ┆          │\n",
       "│ ehens…    ┆ ehens…    ┆ ehens…    ┆ ehens…    ┆   ┆           ┆           ┆           ┆          │\n",
       "│ usgaapAcc ┆ usgaapRet ┆ usgaapRet ┆ usgaapAcc ┆ … ┆ AND       ┆ AND       ┆ AND       ┆ AND      │\n",
       "│ umulatedO ┆ ainedEarn ┆ ainedEarn ┆ umulatedO ┆   ┆           ┆           ┆           ┆          │\n",
       "│ therCompr ┆ ingsMembe ┆ ingsMembe ┆ therCompr ┆   ┆           ┆           ┆           ┆          │\n",
       "│ ehens…    ┆ r         ┆ r         ┆ ehens…    ┆   ┆           ┆           ┆           ┆          │\n",
       "│ usgaapAcc ┆ usgaapRet ┆ usgaapAcc ┆ usgaapCom ┆ … ┆ EXCHANGE  ┆ EXCHANGE  ┆ EXCHANGE  ┆ EXCHANGE │\n",
       "│ umulatedO ┆ ainedEarn ┆ umulatedO ┆ monStockM ┆   ┆           ┆           ┆           ┆          │\n",
       "│ therCompr ┆ ingsMembe ┆ therCompr ┆ ember     ┆   ┆           ┆           ┆           ┆          │\n",
       "│ ehens…    ┆ r         ┆ ehens…    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ …         ┆ …         ┆ …         ┆ …         ┆ … ┆ …         ┆ …         ┆ …         ┆ …        │\n",
       "│ null      ┆ null      ┆ null      ┆ null      ┆ … ┆ null      ┆ null      ┆ null      ┆ null     │\n",
       "│ null      ┆ null      ┆ null      ┆ null      ┆ … ┆ null      ┆ null      ┆ null      ┆ null     │\n",
       "│ null      ┆ null      ┆ null      ┆ null      ┆ … ┆ null      ┆ null      ┆ null      ┆ null     │\n",
       "│ null      ┆ null      ┆ null      ┆ null      ┆ … ┆ null      ┆ null      ┆ null      ┆ null     │\n",
       "│ null      ┆ null      ┆ null      ┆ null      ┆ … ┆ null      ┆ null      ┆ null      ┆ null     │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example series \n",
    "example_series = df_dict['MMM'][df_dict['MMM'].columns[1]]\n",
    "example_df = df_dict['FAST']\n",
    "example_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JPM, 2020-02-25: 103676\n",
      "JPM, 2021-02-23: 136587\n",
      "JPM, 2022-02-22: 125387\n",
      "JPM, 2023-02-21: 124643\n",
      "JPM, 2024-02-16: 134994\n",
      "MRNA, 2020-02-27: 142815\n",
      "MRNA, 2021-02-26: 147655\n",
      "XOM, 2023-05-02: 4704\n",
      "PLUG, 2022-03-14: 138207\n"
     ]
    }
   ],
   "source": [
    "#here I have checked if there ara weird numder of words for reports\n",
    "for company_name, df in df_dict.items():\n",
    "    for col in df:\n",
    "        if col.count() < 5000:\n",
    "            print(f\"{company_name}, {col.name}: {col.count()}\")\n",
    "        elif col.count() > 100000:\n",
    "            print(f\"{company_name}, {col.name}: {col.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the func, that appled to a series and get sentiment words from it. As an output we get a df with first col - grouped words that appeaps in LOUGHRAN dictionary and has >0 value in \"positive\" or \"negative\" cols. Secon col contain count of corresponding word in this document. Third col contain boolean, indicatin if this word has positive sentiment (True) or negative (False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (226, 3)\n",
      "┌─────────────┬──────────────┬──────────┐\n",
      "│ 2019-07-26  ┆ count in doc ┆ positive │\n",
      "│ ---         ┆ ---          ┆ ---      │\n",
      "│ str         ┆ u32          ┆ bool     │\n",
      "╞═════════════╪══════════════╪══════════╡\n",
      "│ contending  ┆ 1            ┆ false    │\n",
      "│ alleges     ┆ 4            ┆ false    │\n",
      "│ unstable    ┆ 1            ┆ false    │\n",
      "│ impairments ┆ 2            ┆ false    │\n",
      "│ injury      ┆ 13           ┆ false    │\n",
      "│ …           ┆ …            ┆ …        │\n",
      "│ enabled     ┆ 1            ┆ true     │\n",
      "│ better      ┆ 8            ┆ true     │\n",
      "│ best        ┆ 7            ┆ true     │\n",
      "│ stable      ┆ 3            ┆ true     │\n",
      "│ satisfy     ┆ 1            ┆ true     │\n",
      "└─────────────┴──────────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "def count_sentiment_w_in_doc(df_series):\n",
    "        \n",
    "        #grouped series that became a df, where each row is unique word and its count in document \n",
    "        num_of_w = df_series.value_counts().rename({\"count\": \"count in doc\"})\n",
    "       \n",
    "        \n",
    "        #first col of this df (only words by itself)\n",
    "        only_w = num_of_w[num_of_w.columns[0]]\n",
    "        \n",
    "\n",
    "        #Filterd df, there is only words that have positive or negative sentiment score in this document \n",
    "        pos_w = num_of_w.filter(only_w.is_in(positive_words)).with_columns(pl.lit(True).alias(\"positive\"))\n",
    "        neg_w = num_of_w.filter(only_w.is_in(negative_words)).with_columns(pl.lit(False).alias(\"positive\"))\n",
    "       \n",
    "        #Staked for one df for further operations \n",
    "        df_stacked = neg_w.vstack(pos_w)\n",
    "\n",
    "        return df_stacked\n",
    "    \n",
    "check = count_sentiment_w_in_doc(df_dict['MMM'][df_dict['MMM'].columns[1]])  \n",
    "print(check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the func that counts a number of docs with at least one occurense of the input word. It takes hole dictionary whith dataframes and particular word as an input. Then checks how many cols in each df contain this word, sum up all resulst and return a single value for each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_all_doc_occurence(check_str, df_dict):\n",
    "    count = 0\n",
    "    for df in df_dict.values():\n",
    "        count += df.select((pl.all() == check_str).sum() > 0).sum_horizontal()[0]\n",
    "        \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "393"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stringg = \"a\"\n",
    "in_all_doc_occurence(stringg, df_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the func that takes a df from count_sentiment_w_in_doc() and for each word in this df applies in_all_doc_occurence(), meaning that it counts all docs with at least one occurence of this word. The result of applying this func for each word in df is a series of integers showing counts for correcdonding word. This series augmented af col named \"count in all docs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_occurence_count(df_series, df_dict):\n",
    "   check = count_sentiment_w_in_doc(df_series).lazy()\n",
    "\n",
    "   counts = check.with_columns(pl.col(check.columns[0]).map_elements(lambda x: in_all_doc_occurence(x, df_dict)).alias(\"count in all docs\")).collect()\n",
    "   return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (226, 4)\n",
      "┌───────────────┬──────────────┬──────────┬───────────────────┐\n",
      "│ 2019-07-26    ┆ count in doc ┆ positive ┆ count in all docs │\n",
      "│ ---           ┆ ---          ┆ ---      ┆ ---               │\n",
      "│ str           ┆ u32          ┆ bool     ┆ i64               │\n",
      "╞═══════════════╪══════════════╪══════════╪═══════════════════╡\n",
      "│ alleges       ┆ 4            ┆ false    ┆ 183               │\n",
      "│ negatively    ┆ 3            ┆ false    ┆ 284               │\n",
      "│ punitive      ┆ 16           ┆ false    ┆ 126               │\n",
      "│ opposed       ┆ 1            ┆ false    ┆ 84                │\n",
      "│ liquidation   ┆ 1            ┆ false    ┆ 123               │\n",
      "│ …             ┆ …            ┆ …        ┆ …                 │\n",
      "│ improvements  ┆ 4            ┆ true     ┆ 261               │\n",
      "│ strengthening ┆ 1            ┆ true     ┆ 98                │\n",
      "│ enable        ┆ 7            ┆ true     ┆ 272               │\n",
      "│ efficient     ┆ 2            ┆ true     ┆ 195               │\n",
      "│ stability     ┆ 1            ┆ true     ┆ 139               │\n",
      "└───────────────┴──────────────┴──────────┴───────────────────┘\n"
     ]
    }
   ],
   "source": [
    "res_df = total_occurence_count(example_series, df_dict)\n",
    "print(res_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the func that takes as an argument resulting df, wich was obtained from total_occurence_count(). Recal that this df contains information about one document (one col in df). This func calculate weighted and raw scores using precomputed metrics. Returns a list with weighted score and raw score. Weights are calculated based on this formula: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "w_{i,j} = \n",
    "\\begin{cases} \n",
    "\\left(\\frac{1 + \\log(tf_{i,j})}{1 + \\log(a)}\\right) \\log\\left(\\frac{N}{df_i}\\right) & \\text{if } tf_{i,j} \\geq 1 \\\\\n",
    "0 & \\text{otherwise} \n",
    "\\end{cases}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N represents the total number of 10-Ks in the sample, dfi the number of documents containing at least one occurrence of the i th word, tfi,j the raw count of the i th word in the j th document, and a the average word count in the document.\n",
    "\n",
    "The formula is from:\n",
    "\n",
    "Loughran T., McDonald B. When is a liability not a liability? Textual analysis, dictionaries, and 10‐Ks //The Journal of finance. – 2011. – Т. 66. – №. 1. – С. 35-65."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_score(res_df):\n",
    "\n",
    "    res_df.lazy()\n",
    "\n",
    "    res = res_df.with_columns((((1 + pl.col(res_df.columns[1]).log())/(1 + ln_average_word_count))*((total_num_of_rep/pl.col(res_df.columns[3])).log())).alias(\"metrics\"))\n",
    "\n",
    "    w_pos_sen = res.filter(pl.col('positive') == True).select(pl.col(res.columns[4])).sum().item()\n",
    "    w_neg_sen = res.filter(pl.col('positive') == False).select(pl.col(res.columns[4])).sum().item()\n",
    "\n",
    "    w_score = w_pos_sen - w_neg_sen\n",
    "    score = res.select(pl.col('positive')).sum().item()*2 - len(res)\n",
    "\n",
    "    scores = [w_score, score]\n",
    "    \n",
    "    return scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the function that takes polars series as an input, then concatinate all values in the single string. For this sitring, which is the initial report, this func calculates sentiment scores according to Harvard IV-4 and Loughran and McDonald Financial Sentiment Dictionaries. Perticulary, this function calculates polarity score which is defined by the following formula:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "Polarity = \\frac{N_{\\text{pos}} - N_{\\text{neg}}}{N_{\\text{pos}} + N_{\\text{neg}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiv4 = ps.HIV4()\n",
    "lm = ps.LM() \n",
    "\n",
    "def compute_pysentiment(series):\n",
    "\n",
    "    doc_string = series.str.concat(\" \", ignore_nulls=True)\n",
    "\n",
    "    tokens_hiv4 = hiv4.tokenize(doc_string[0])\n",
    "    tokens_lm = lm.tokenize(doc_string[0])\n",
    "\n",
    "    score_hiv4 = hiv4.get_score(tokens_hiv4)\n",
    "    score_lm = lm.get_score(tokens_lm)\n",
    "\n",
    "  \n",
    "    return score_lm[\"Polarity\"], score_hiv4[\"Polarity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 48.0303, 334, 'extended values starts from here:', -0.49927641063728184, 0.4112870482315698]\n"
     ]
    }
   ],
   "source": [
    "#Example of pysentiment2 working on example_series: first value is \"Polsrity\" score from Loughran-McDonald dictionary, and second one is from Harvard dictionary\n",
    "lst = [1, 48.0303, 334, 'extended values starts from here:']\n",
    "\n",
    "lst.extend(compute_pysentiment(example_series))\n",
    "\n",
    "print(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General loop that iterates over dfs and over it columns. It uses predefined finctions to calculate scores and save it as parquet files. Each parquet file named with company name is a dataframe with col names as field dates, first row is weighted scores and second row is raw scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration for AAPL is done successfully\n",
      "Attempting to write to: data\\full_10_Q_scores\\AAPL_full_doc_sen_score_df.parquet\n",
      "data\\full_10_Q_scores\\AAPL_full_doc_sen_score_df.parquet created successfully\n",
      "Iteration for MSFT is done successfully\n",
      "Attempting to write to: data\\full_10_Q_scores\\MSFT_full_doc_sen_score_df.parquet\n",
      "data\\full_10_Q_scores\\MSFT_full_doc_sen_score_df.parquet created successfully\n",
      "Iteration for BIGC is done successfully\n",
      "Attempting to write to: data\\full_10_Q_scores\\BIGC_full_doc_sen_score_df.parquet\n",
      "data\\full_10_Q_scores\\BIGC_full_doc_sen_score_df.parquet created successfully\n",
      "Iteration for ROKU is done successfully\n",
      "Attempting to write to: data\\full_10_Q_scores\\ROKU_full_doc_sen_score_df.parquet\n",
      "data\\full_10_Q_scores\\ROKU_full_doc_sen_score_df.parquet created successfully\n",
      "Iteration for JPM is done successfully\n",
      "Attempting to write to: data\\full_10_Q_scores\\JPM_full_doc_sen_score_df.parquet\n",
      "data\\full_10_Q_scores\\JPM_full_doc_sen_score_df.parquet created successfully\n",
      "Iteration for V is done successfully\n",
      "Attempting to write to: data\\full_10_Q_scores\\V_full_doc_sen_score_df.parquet\n",
      "data\\full_10_Q_scores\\V_full_doc_sen_score_df.parquet created successfully\n",
      "Iteration for SQ is done successfully\n",
      "Attempting to write to: data\\full_10_Q_scores\\SQ_full_doc_sen_score_df.parquet\n",
      "data\\full_10_Q_scores\\SQ_full_doc_sen_score_df.parquet created successfully\n",
      "Iteration for HOOD is done successfully\n",
      "Attempting to write to: data\\full_10_Q_scores\\HOOD_full_doc_sen_score_df.parquet\n",
      "data\\full_10_Q_scores\\HOOD_full_doc_sen_score_df.parquet created successfully\n",
      "Iteration for JNJ is done successfully\n",
      "Attempting to write to: data\\full_10_Q_scores\\JNJ_full_doc_sen_score_df.parquet\n",
      "data\\full_10_Q_scores\\JNJ_full_doc_sen_score_df.parquet created successfully\n",
      "Iteration for PFE is done successfully\n",
      "Attempting to write to: data\\full_10_Q_scores\\PFE_full_doc_sen_score_df.parquet\n",
      "data\\full_10_Q_scores\\PFE_full_doc_sen_score_df.parquet created successfully\n",
      "Iteration for MRNA is done successfully\n",
      "Attempting to write to: data\\full_10_Q_scores\\MRNA_full_doc_sen_score_df.parquet\n",
      "data\\full_10_Q_scores\\MRNA_full_doc_sen_score_df.parquet created successfully\n",
      "Iteration for TDOC is done successfully\n",
      "Attempting to write to: data\\full_10_Q_scores\\TDOC_full_doc_sen_score_df.parquet\n",
      "data\\full_10_Q_scores\\TDOC_full_doc_sen_score_df.parquet created successfully\n",
      "Iteration for XOM is done successfully\n",
      "Attempting to write to: data\\full_10_Q_scores\\XOM_full_doc_sen_score_df.parquet\n",
      "data\\full_10_Q_scores\\XOM_full_doc_sen_score_df.parquet created successfully\n",
      "Iteration for CVX is done successfully\n",
      "Attempting to write to: data\\full_10_Q_scores\\CVX_full_doc_sen_score_df.parquet\n",
      "data\\full_10_Q_scores\\CVX_full_doc_sen_score_df.parquet created successfully\n",
      "Iteration for FSLR is done successfully\n",
      "Attempting to write to: data\\full_10_Q_scores\\FSLR_full_doc_sen_score_df.parquet\n",
      "data\\full_10_Q_scores\\FSLR_full_doc_sen_score_df.parquet created successfully\n",
      "Iteration for PLUG is done successfully\n",
      "Attempting to write to: data\\full_10_Q_scores\\PLUG_full_doc_sen_score_df.parquet\n",
      "data\\full_10_Q_scores\\PLUG_full_doc_sen_score_df.parquet created successfully\n",
      "Iteration for GE is done successfully\n",
      "Attempting to write to: data\\full_10_Q_scores\\GE_full_doc_sen_score_df.parquet\n",
      "data\\full_10_Q_scores\\GE_full_doc_sen_score_df.parquet created successfully\n",
      "Iteration for MMM is done successfully\n",
      "Attempting to write to: data\\full_10_Q_scores\\MMM_full_doc_sen_score_df.parquet\n",
      "data\\full_10_Q_scores\\MMM_full_doc_sen_score_df.parquet created successfully\n",
      "Iteration for CAT is done successfully\n",
      "Attempting to write to: data\\full_10_Q_scores\\CAT_full_doc_sen_score_df.parquet\n",
      "data\\full_10_Q_scores\\CAT_full_doc_sen_score_df.parquet created successfully\n",
      "Iteration for FAST is done successfully\n",
      "Attempting to write to: data\\full_10_Q_scores\\FAST_full_doc_sen_score_df.parquet\n",
      "data\\full_10_Q_scores\\FAST_full_doc_sen_score_df.parquet created successfully\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for company_name, df in df_dict.items():\n",
    "\n",
    "    score_dict = {}\n",
    "\n",
    "    for col in df:\n",
    "        \n",
    "        res_df = total_occurence_count(col, df_dict)\n",
    "        scores = compute_score(res_df)\n",
    "\n",
    "        scores.extend(compute_pysentiment(col))\n",
    "\n",
    "        score_dict[col.name] = scores\n",
    "    \n",
    "    df = pl.DataFrame(score_dict)\n",
    "    \n",
    "    print(f'Iteration for {company_name} is done successfully')\n",
    "\n",
    " # Determine the output directory and file name\n",
    "    output_dir = os.path.join('data', 'full_10_Q_scores')\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    file_name_new = f\"{company_name}_full_doc_sen_score_df.parquet\"\n",
    "    full_path = os.path.join(output_dir, file_name_new)\n",
    "    full_path = os.path.normpath(full_path)\n",
    "\n",
    "    print(f\"Attempting to write to: {full_path}\")\n",
    "\n",
    "    # Write the DataFrame to Parquet\n",
    "    df.write_parquet(full_path)\n",
    "\n",
    "    print(f\"{full_path} created successfully\")\n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
