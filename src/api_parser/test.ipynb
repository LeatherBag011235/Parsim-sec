{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fake_useragent import UserAgent\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_headers():\n",
    "    ua = UserAgent()\n",
    "    headers = {'User-Agent': ua.random}\n",
    "    return headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# URL to the EDGAR filing\n",
    "url = \"https://www.sec.gov/Archives/edgar/data/102909/0001104659-20-018237.txt\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url, headers=get_random_headers())\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    content = response.text\n",
    "    print(content)  # or process the content as needed\n",
    "else:\n",
    "    print(\"Failed to retrieve the document\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a name=\"gg_002\"></a>\n",
      "<a name=\"gg_003\"></a>\n",
      "<b>ITEM\n",
      "2. MANAGEMENT’S DISCUSSION AND ANALYSIS OF FINANCIAL CONDITION AND RESULTS OF OPERATIONS.</b>\n",
      "<b>ITEM\n",
      "2. MANAGEMENT’S DISCUSSION AND ANALYSIS OF FINANCIAL CONDITION AND RESULTS OF OPERATIONS.</b>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.sec.gov/Archives/edgar/data/1015383/0001493152-20-002565.txt\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url, headers=get_random_headers())\n",
    "\n",
    "response.raise_for_status()  # Ensure the request was successful\n",
    "\n",
    "# Create a BeautifulSoup object\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find the starting point\n",
    "    start_anchor = soup.find('a', attrs={'name': 'gg_002'})\n",
    "    print(start_anchor)\n",
    "    # Find the endpoint\n",
    "    end_anchor = soup.find('a', attrs={'name': 'gg_003'})\n",
    "    print(end_anchor)\n",
    "\n",
    "    # Variable to hold all relevant paragraphs\n",
    "    content = []\n",
    "\n",
    "    if start_anchor and end_anchor:\n",
    "        # Start collecting the content from the next sibling of start_anchor\n",
    "        element = start_anchor.find_next_sibling()\n",
    "        print(element)\n",
    "\n",
    "        while element and element != end_anchor:\n",
    "            print(element)\n",
    "            if element.name == 'p':\n",
    "                content.append(element.get_text(strip=True))\n",
    "            element = element.find_next_sibling()\n",
    "\n",
    "        # Join the paragraphs with new lines to form the complete section\n",
    "        full_text = \"\\n\".join(content)\n",
    "        print(full_text)\n",
    "    else:\n",
    "        print(\"Start or end anchor not found.\")\n",
    "\n",
    "else:\n",
    "    print(\"Failed to retrieve the document\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
