{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import unidecode\n",
    "import re\n",
    "from sec_downloader import Downloader\n",
    "\n",
    "import requests\n",
    "from fake_useragent import UserAgent\n",
    "import unicodedata\n",
    "import html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_headers():\n",
    "    ua = UserAgent()\n",
    "    headers = {'User-Agent': ua.random}\n",
    "    return headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\310\\AppData\\Local\\Temp\\ipykernel_4428\\812151145.py:1: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  soup = BeautifulSoup(get_html(\"AAPL\", \"10-K\"))\n"
     ]
    }
   ],
   "source": [
    "#soup = BeautifulSoup(get_html(\"AAPL\", \"10-K\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.sec.gov/Archives/edgar/data/0000200406/000020040620000010/form10-k20191229.htm\"\n",
    "\n",
    "response = requests.get(url, headers=get_random_headers())\n",
    "response.raise_for_status()  # Check that the request was successful\n",
    "\n",
    "# Parse the HTML with BeautifulSoup\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "## Find all the table tags and decompose them to remove from the soup\n",
    "#for table in soup.find_all('table'):\n",
    "#    table.decompose()\n",
    "#\n",
    "## Now the soup object doesn't contain the tables, you can extract text\n",
    "#text = soup.get_text(separator=' ', strip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>Document</title>\n"
     ]
    }
   ],
   "source": [
    "print(soup.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "544094 Document false--12-29FY20190000200406P3Y0.0200.0200.0100.0102480000002260000003.323.543.7511432000000043200000003119843000311984300031198430001000000000750000000750000000150000000010000000005000000001000000000750000000750000000150000000010000000005000000000.00250.006500.00890.011250.011500.01650.01650.018750.01950.02050.02250.02450.02450.026250.0290.02950.02950.033750.034000.035000.03550.03550.036250.0370.03750.030.043750.0450.0450.04750.04850.04950.0550.05850.05950.06730.06950.002500.006500.011500.01650.01650.01950.02050.02250.02450.02450.026250.0290.02950.02950.033750.034000.035000.03550.03550.036250.0370.03750.030.043750.0450.0450.04850.04950.0550.05850.05950.06730.0695next 12 months0.211.141.141.141.141.141.26361.10961.10961.10961.10961.10961.2987100000010000002020-09-102019-09-122360000001900000083000000400000022200000019100000070000000270000009600000000002000000200000000P20YP30YP13YP10YP20YP2YP3Y131.94115.6758.65100.0672.54141.06129.5166.07101.8790.44 0000200406 2018-12-31 2019-1\n"
     ]
    }
   ],
   "source": [
    "text = soup.get_text()\n",
    "text = unidecode.unidecode(text)\n",
    "text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "print(len(text), text[:1000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pattern_mnda = r\"(?i)item\\s+\\d+[A-Za-z]?\\.?\\s*(?:--|[-—])?\\s*management[’'`]s\\s+discussion\\s+and\\s+analysis\\s+of\\s+(?:financial\\s+condition\\s+and\\s+results\\s+of\\s+operations|results\\s+of\\s+operations\\s+and\\s+financial\\s+condition)\"\n",
    "\n",
    "\n",
    "pattern_qnq = r\"(?i)item\\s+\\d+[A-Za-z]?\\.?\\s*(?:--|[-—])?\\s*(?:quantitative\\s+and\\s+qualitative|qualitative\\s+and\\s+quantitative)?\\s+disclosures\\s+about\\s+market\\s+risk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Item 7. Management's Discussion and Analysis of Results of Operations and Financial Condition\", \"Item 7. Management's Discussion and Analysis of Results of Operations and Financial Condition\", \"Item 7.MANAGEMENT'S DISCUSSION AND ANALYSIS OF RESULTS OF OPERATIONS AND FINANCIAL CONDITION\", \"Item 7. Management's Discussion and Analysis of Results of Operations and Financial Condition\", \"Item 7. Management's Discussion and Analysis of Results of Operations and Financial Condition\"] \n",
      " ['Item 7A.QUANTITATIVE AND QUALITATIVE DISCLOSURES ABOUT MARKET RISK']\n"
     ]
    }
   ],
   "source": [
    "matches_mnda = re.findall(pattern_mnda, text)\n",
    "matches_qnq = re.findall(pattern_qnq, text)\n",
    "print(matches_mnda, '\\n', matches_qnq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnda: 122922\n",
      "mnda: 171395\n",
      "mnda: 189250\n",
      "mnda: 193988\n",
      "mnda: 254360\n",
      "qnq: 254121\n"
     ]
    }
   ],
   "source": [
    "matches_mnda = re.finditer(pattern_mnda, text)\n",
    "matches_qnq = re.finditer(pattern_qnq, text)\n",
    "\n",
    "for i, mnda in enumerate(matches_mnda):\n",
    "    print(f'mnda: {mnda.end()}')\n",
    "for x, qnq in enumerate(matches_qnq):\n",
    "    print(f'qnq: {qnq.start()}')\n",
    "    \n",
    "    \n",
    "    #print(f'mnda №{i+1}:{mnda.span()} qnq №{x+1}: {qnq.span()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The longest substring found is: '131199'\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def find_longest_substring(text, pattern_mnda, pattern_qnq):\n",
    "    matches_mnda = list(re.finditer(pattern_mnda, text))\n",
    "    matches_qnq = list(re.finditer(pattern_qnq, text))\n",
    "    \n",
    "    longest_substring = \"\"\n",
    "    \n",
    "    for mnda_match in matches_mnda:\n",
    "        mnda_end = mnda_match.end()\n",
    "        # Find the first matches_qnq after this mnda_match\n",
    "        for qnq_match in matches_qnq:\n",
    "            if qnq_match.start() > mnda_end:\n",
    "                substring = text[mnda_end:qnq_match.start()]\n",
    "                if len(substring) > len(longest_substring):\n",
    "                    longest_substring = substring\n",
    "                break  # We only want the first qnq match after each mnda match\n",
    "    \n",
    "    return longest_substring\n",
    "\n",
    "# Example usage\n",
    "longest = find_longest_substring(text, pattern_mnda, pattern_qnq)\n",
    "print(f\"The longest substring found is: '{len(longest)}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "756 Item 2 -- MANAGEMENT'S DISCUSSION AND ANALYSIS OF FINANCIAL CONDITION AND RESULTS OF OPERATIONS Item 10. Management's Discussion and Analysis of Financial Condition and Results of Operations Item 2A. Management's Discussion and Analysis of Financial Condition and Results of Operations. Item 7. Management's Discussion and Analysis of Financial Condition and Results of Operations ITEM 7. MANAGEMENT'S DISCUSSION AND ANALYSIS OF FINANCIAL CONDITION AND RESULTS OF OPERATIONS Item 7. MANAGEMENT'S DISCUSSION AND ANALYSIS OF FINANCIAL CONDITION AND RESULTS OF OPERATIONS Item 7. Management's Discussion and Analysis of Financial Condition and Results of Operations Item 7. MANAGEMENT'S DISCUSSION AND ANALYSIS OF RESULTS OF OPERATIONS AND FINANCIAL CONDITION\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Assuming 'text' is the variable containing the text extracted from your document\n",
    "text = \"\"\"\n",
    "Item 2 — MANAGEMENT’S DISCUSSION AND ANALYSIS OF FINANCIAL CONDITION AND RESULTS OF OPERATIONS\n",
    "\n",
    "Item 10.    Management’s Discussion and Analysis of Financial Condition and Results of Operations\n",
    "\n",
    "Item 2A.    Management's Discussion and Analysis of Financial Condition and Results of Operations.\n",
    "\n",
    "Item 7. Management’s Discussion and Analysis of Financial Condition and Results of Operations\n",
    "\n",
    "ITEM 7. MANAGEMENT'S DISCUSSION AND ANALYSIS OF FINANCIAL CONDITION AND RESULTS OF OPERATIONS\n",
    "\n",
    "Item 7.\t\n",
    "MANAGEMENT’S DISCUSSION AND ANALYSIS OF FINANCIAL CONDITION AND RESULTS OF OPERATIONS\n",
    "\n",
    "Item 7. Management’s Discussion and Analysis of Financial Condition and Results of Operations\n",
    "\n",
    "Item 7.\n",
    "MANAGEMENT’S DISCUSSION AND ANALYSIS OF RESULTS OF OPERATIONS AND FINANCIAL CONDITION\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "text = unidecode.unidecode(text)\n",
    "text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "print(len(text), text)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "\n",
      "\n",
      "False\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#pattern_mnda = r\"(?i)item\\s+\\d+[A-Za-z]?\\.?\\s*(?:--|[-—])?\\s*management[’'`]s\\s+discussion\\s+and\\s+analysis\\s+of\\s+financial\\s+condition\\s+and\\s+results\\s+of\\s+operations\"\n",
    "#test for either order\n",
    "pattern_mnda = r\"(?i)^\\s*item\\s+\\d+[A-Za-z]?\\.?\\s*(?:--|[-—])?\\s*management[’'`]s\\s+discussion\\s+and\\s+analysis\\s+of\\s+(?:financial\\s+condition\\s+and\\s+results\\s+of\\s+operations|results\\s+of\\s+operations\\s+and\\s+financial\\s+condition)\\s*$\"\n",
    "\n",
    "matches = re.findall(pattern_mnda, text, re.MULTILINE)\n",
    "print(matches)\n",
    "print('\\n')\n",
    "print(len(matches) == 8)\n",
    "print(len(matches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
